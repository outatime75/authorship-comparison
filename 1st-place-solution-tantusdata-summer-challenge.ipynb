{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Tantus competition - Authorship comparison","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom sentence_transformers import SentenceTransformer, util\n\nfrom sklearn.metrics import pairwise_distances\n\nimport os\nimport random\nimport tqdm\n\nfrom itertools import combinations\nfrom Levenshtein import distance","metadata":{"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"CUDA is available.\")\nelse:\n    print(\"CUDA is not available.\")","metadata":{},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"CUDA is available.\n"}]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 80)\npd.set_option('display.max_rows', 70)\n# Set the maximum column width to a larger value (e.g., 100 characters)\npd.set_option('display.max_colwidth', 100)\n\nnp.set_printoptions(suppress=True)\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"tags":[]},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = Path('/home/kcini75/Notebooks/Tantus competition')\nSEED = 553\n\n# Set seed for Python's random module\nrandom.seed(SEED)\n\n# Set seed for NumPy\nnp.random.seed(SEED)\n\n# Set seed for PyTorch (both CPU and CUDA)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"tags":[]},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Loading datasets\n\ntrain_df_full = pd.read_csv(DATA_DIR / 'train.csv')\ntest_df = pd.read_csv(DATA_DIR / 'test.csv')\ntest_texts_df = pd.read_csv(DATA_DIR / 'test_texts.csv')\nsample_submission_df = pd.read_csv(DATA_DIR / 'sample_submission.csv')","metadata":{"tags":[]},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Checking if there are duplicates within the author sets\n\n# Create a copy of the original DataFrame to store results\nfiltered_df = train_df_full.copy()\n\nfor auth in train_df_full.author.unique():\n    temp_df = train_df_full[train_df_full.author == auth]\n    \n    # Column for storing distances\n    distance_results = []\n\n    # Get the column data\n    column_data = temp_df['content'].tolist()\n\n    # Calculate Levenshtein distance for all combinations\n    for pair in combinations(column_data, 2):\n        str1, str2 = pair\n        dist = distance(str1, str2)\n        if dist < 50:\n            distance_results.append((str1, str2, dist))\n            \n            # Keep track of strings that need to be removed\n            filtered_df = filtered_df[(filtered_df['author'] != auth) | (filtered_df['content'] != str1)]\n\n    # Create a DataFrame from the results\n    distance_df = pd.DataFrame(distance_results, columns=['text1', 'text2', 'levenshtein_distance'])\n\n    # Print the resulting DataFrame\n    if distance_results:\n        print(f'Levensthein distance for Author {auth}')\n        print('---------------------------------------')\n        print(str(distance_df))\n        print()\n    \n    ","metadata":{"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"Levensthein distance for Author 26\n\n---------------------------------------\n\n                                                                                                 text1  \\\n\n0  Czech Prime Minister Vaclav Klaus announced a state commission on Wednesday to attack bureaucrac...   \n\n1  The Czech Statistical Bureau (CSU) said on Thursday it would change its methodology for calculat...   \n\n\n\n                                                                                                 text2  \\\n\n0  Czech Prime Minister Vaclav Klaus announced a state commission on Wednesday to attack bureaucrac...   \n\n1  The Czech Statistical Bureau\\n(CSU) said on Thursday it would change its methodology for\\ncalcul...   \n\n\n\n   levenshtein_distance  \n\n0                    42  \n\n1                    40  \n\n\n\nLevensthein distance for Author 20\n\n---------------------------------------\n\n                                                                                                 text1  \\\n\n0  The Internet continued to grow in leaps and bounds this year while online services found it much...   \n\n\n\n                                                                                                 text2  \\\n\n0  The Internet continued to grow in leaps and bounds this year while online services found it much...   \n\n\n\n   levenshtein_distance  \n\n0                    13  \n\n\n\nLevensthein distance for Author 21\n\n---------------------------------------\n\n                                                                                                 text1  \\\n\n0  Czech paper concern Sepap Group a.s. on Friday said its nine-month net profit fell as a shutdown...   \n\n\n\n                                                                                                 text2  \\\n\n0  Czech paper concern Sepap Group a.s. on Friday said its nine-month net profit fell as a shutdown...   \n\n\n\n   levenshtein_distance  \n\n0                    41  \n\n\n\nLevensthein distance for Author 15\n\n---------------------------------------\n\n                                                                                                 text1  \\\n\n0                  OEF  &#151; Capt. Daniel G. McCollum, 29, of Richland, South Carolina, was kille...   \n\n1                  OEF  &#151; Capt. Daniel G. McCollum, 29, of Richland, South Carolina, was kille...   \n\n2                  OEF  &#151; Staff Sgt. Scott N. Germosen, 37, of Queens, New York, was killed on...   \n\n3                  OEF  &#151; Staff Sgt. Scott N. Germosen, 37, of Queens, New York, was killed on...   \n\n4                  OEF  &#151; Army Ranger Pfc. Kristofor T. Stonesifer, 28, of Missoula, Montana, ...   \n\n5                  OEF  &#151; Sgt. Jeannette L. Winters, 25, of Du Page, Illinois, was killed on J...   \n\n6                  OEF  &#151; Army Master Sergeant Jefferson Donald Davis, 39, of Tennessee, was k...   \n\n\n\n                                                                                                 text2  \\\n\n0                  OEF  &#151; Sgt. Jeannette L. Winters, 25, of Du Page, Illinois, was killed on J...   \n\n1                  OEF  &#151; Sgt. Nathan P. Hays, 21, of Lincoln, Washington, was killed on Janua...   \n\n2                  OEF  &#151; Sgt. Jeannette L. Winters, 25, of Du Page, Illinois, was killed on J...   \n\n3                  OEF  &#151; Sgt. Nathan P. Hays, 21, of Lincoln, Washington, was killed on Janua...   \n\n4                  OEF  &#151; Army Ranger Spc. Jonn J. Edmunds, 20, of Cheyenne, Wyoming, died on ...   \n\n5                  OEF  &#151; Sgt. Nathan P. Hays, 21, of Lincoln, Washington, was killed on Janua...   \n\n6                  OEF  &#151; Army Staff Sergeant Brian Cody Prosser, 28, of California, was kille...   \n\n\n\n   levenshtein_distance  \n\n0                    46  \n\n1                    42  \n\n2                    45  \n\n3                    46  \n\n4                    35  \n\n5                    37  \n\n6                    43  \n\n\n\nLevensthein distance for Author 18\n\n---------------------------------------\n\n                                                                                                 text1  \\\n\n0          urlLink     What Type Of Retro Gal Are You?     brought to you by  urlLink Quizilla     ...   \n\n1          urlLink     What Type Of Retro Gal Are You?     brought to you by  urlLink Quizilla     ...   \n\n2          urlLink     What Type Of Retro Gal Are You?     brought to you by  urlLink Quizilla     ...   \n\n3          urlLink     What Office Space character are you?     brought to you by  urlLink Quizilla...   \n\n4          urlLink     What Office Space character are you?     brought to you by  urlLink Quizilla...   \n\n5          urlLink     Which Personality Disorder Do You Have?     brought to you by  urlLink Quizi...   \n\n\n\n                                                                                                 text2  \\\n\n0          urlLink     What Office Space character are you?     brought to you by  urlLink Quizilla...   \n\n1          urlLink     Which Personality Disorder Do You Have?     brought to you by  urlLink Quizi...   \n\n2          urlLink     What Sign of Affection Are You?     brought to you by  urlLink Quizilla     ...   \n\n3          urlLink     Which Personality Disorder Do You Have?     brought to you by  urlLink Quizi...   \n\n4          urlLink     What Sign of Affection Are You?     brought to you by  urlLink Quizilla     ...   \n\n5          urlLink     What Sign of Affection Are You?     brought to you by  urlLink Quizilla     ...   \n\n\n\n   levenshtein_distance  \n\n0                    20  \n\n1                    30  \n\n2                    14  \n\n3                    31  \n\n4                    20  \n\n5                    28  \n\n\n"}]},{"cell_type":"markdown","source":"The above shows that Authors 26, 20, 21, 15 and 18 have multiple similar entries. The filtered_df dataframe will only contain those strings that are not duplicated. ","metadata":{}},{"cell_type":"code","source":"train_df_full = filtered_df.reset_index(drop=True)","metadata":{"tags":[]},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Correcting the dataset","metadata":{}},{"cell_type":"code","source":"# Removing one of the duplicated authors\n# 19 and 1 are duplicated\n# 8,9 and 10 are duplicated\n# 13 and 14 are duplicated\n\ntrain_df_full = train_df_full.drop(train_df_full[train_df_full.author==19].index)\ntrain_df_full = train_df_full.drop(train_df_full[train_df_full.author==9].index)\ntrain_df_full = train_df_full.drop(train_df_full[train_df_full.author==10].index)\ntrain_df_full = train_df_full.drop(train_df_full[train_df_full.author==14].index)","metadata":{"tags":[]},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df_full.reset_index(inplace=True, drop=True)","metadata":{"tags":[]},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"author_sorted = np.sort(train_df_full.author.unique())","metadata":{"tags":[]},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Creating a mapping so that authors(labels) are in ascending order due to compute metrics in the training phase\n# Create a mapping dictionary\n\nmapping_dict = {}\nnew_value = 0\nfor original_value in sorted(author_sorted):\n    mapping_dict[original_value] = new_value\n    new_value += 1\n\n# Print the mapping dictionary\nprint(mapping_dict)","metadata":{"tags":[]},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 11: 9, 12: 10, 13: 11, 15: 12, 16: 13, 17: 14, 18: 15, 20: 16, 21: 17, 22: 18, 23: 19, 24: 20, 25: 21, 26: 22, 27: 23, 28: 24, 29: 25, 30: 26, 31: 27, 32: 28, 33: 29, 34: 30, 35: 31, 36: 32, 37: 33, 38: 34, 39: 35, 40: 36, 41: 37}\n"}]},{"cell_type":"code","source":"train_df_full.author = train_df_full.author.map(mapping_dict)","metadata":{"tags":[]},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"np.sort(train_df_full.author.unique())","metadata":{"tags":[]},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37])"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"import re\n\n# Used gensim library for preprocessing\nfrom gensim.parsing.preprocessing import remove_stopwords\nfrom gensim.parsing.preprocessing import strip_numeric","metadata":{"tags":[]},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n       \n    # Lowercase the text\n    text = text.lower()\n        \n    # Handle contractions\n    contractions = {\n    \"don't\": \"do not\",\n    \"can't\": \"cannot\",\n    \"won't\": \"will not\",\n    \"isn't\": \"is not\",\n    \"aren't\": \"are not\",\n    \"haven't\": \"have not\",\n    \"hasn't\": \"has not\",\n    \"didn't\": \"did not\",\n    \"doesn't\": \"does not\",\n    \"wouldn't\": \"would not\",\n    \"couldn't\": \"could not\",\n    \"shouldn't\": \"should not\",\n    \"wasn't\": \"was not\",\n    \"weren't\": \"were not\",\n    \"mightn't\": \"might not\",\n    \"mustn't\": \"must not\",\n    \"shan't\": \"shall not\",\n    \"it's\": \"it is\",\n    \"he's\": \"he is\",\n    \"she's\": \"she is\",\n    \"that's\": \"that is\",\n    \"there's\": \"there is\",\n    \"what's\": \"what is\",\n    \"who's\": \"who is\",\n    \"let's\": \"let us\",\n    \"you're\": \"you are\",\n    \"we're\": \"we are\",\n    \"they're\": \"they are\",\n    \"I'm\": \"I am\",\n    \"I've\": \"I have\",\n    \"I'll\": \"I will\",\n    # Add more contractions here\n}\n    \n    for contraction, expansion in contractions.items():\n        text = text.replace(contraction, expansion)\n            \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s.]', ' ', text)\n    \n    # Remove stopwords\n    text = remove_stopwords(text)\n    \n    # Remove numbers\n    text = strip_numeric(text)\n    \n    # Remove extra white spaces and full stops\n    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n    text = re.sub(r'\\.', ' ', text)  # Replace dots with white space\n\n        \n    # Remove newline characters\n    text = text.replace('\\n', ' ')\n    \n    # Strip white space\n    text = text.strip()\n    \n    \n    return text","metadata":{"tags":[]},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df_full['content'] = train_df_full.content.apply(preprocess_text)","metadata":{"tags":[]},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df_full.head()","metadata":{"tags":[]},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8</td>\n","      <td>future man  fonz feed reader google look boa rss feed  ll look like email program open somesuch</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33</td>\n","      <td>carnival corp shopping europe acquisitions partners boost number passengers cruise ships industr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20</td>\n","      <td>smiths industries plc said wednesday million acquisition leland electrosystems u s  offered perf...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>24</td>\n","      <td>british private client stockbroker fund manager capel cure myers capital management said thursda...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25</td>\n","      <td>international specialty chemicals group btp plc said wednesday expected profit margins key adhes...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   author  \\\n","0       8   \n","1      33   \n","2      20   \n","3      24   \n","4      25   \n","\n","                                                                                               content  \n","0      future man  fonz feed reader google look boa rss feed  ll look like email program open somesuch  \n","1  carnival corp shopping europe acquisitions partners boost number passengers cruise ships industr...  \n","2  smiths industries plc said wednesday million acquisition leland electrosystems u s  offered perf...  \n","3  british private client stockbroker fund manager capel cure myers capital management said thursda...  \n","4  international specialty chemicals group btp plc said wednesday expected profit margins key adhes...  "]},"metadata":{}}]},{"cell_type":"markdown","source":"### Checking embedding lengths","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoConfig","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this section I have checked whether the tokenized text exceeds the max length for embeddings for the selected model. Following text preprocessing none of the training text content exceeded the maximum length. ","metadata":{}},{"cell_type":"code","source":"model_name = 'intfloat/e5-small-v2' \n\n# Load the tokenizer and configuration\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = AutoConfig.from_pretrained(model_name)\nmax_seq_length = config.max_position_embeddings\n\nfor i in range(len(train_df_full)):\n\n    author = train_df_full.author.loc[i]\n    text = train_df_full.content.loc[i]\n    \n    # Tokenize the text\n    tokens = tokenizer.encode(text, add_special_tokens=True)\n\n    # Check if the token count exceeds the maximum sequence length\n    \n    token_count = len(tokens)\n\n    if token_count > max_seq_length:\n        print(f'{author} : {text}')\n    ","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create train / evaluation sets","metadata":{}},{"cell_type":"code","source":"EVAL_SIZE = 0.2\n\ntrain_df, eval_df = train_test_split(train_df_full, test_size=EVAL_SIZE, stratify=train_df_full['author'], random_state = SEED)#\ntrain_df.reset_index(drop=True, inplace=True)\neval_df.reset_index(drop=True, inplace=True)\n\nprint(len(train_df)) \nprint(len(eval_df))","metadata":{"tags":[]},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"292\n\n74\n"}]},{"cell_type":"markdown","source":"### Create model","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, models","metadata":{"tags":[]},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"CHOSEN_MODEL = 'intfloat/e5-small-v2'","metadata":{"tags":[]},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model1 = SentenceTransformer(CHOSEN_MODEL, device=device)","metadata":{"tags":[]},"execution_count":22,"outputs":[{"name":"stderr","output_type":"stream","text":"2023-09-14 16:15:34.732679: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n\n2023-09-14 16:15:34.763624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n2023-09-14 16:15:35.244512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"}]},{"cell_type":"markdown","source":"### Create training and evaluation pairs","metadata":{"tags":[]}},{"cell_type":"code","source":"from collections import namedtuple\nfrom typing import List, Set","metadata":{"tags":[]},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"TrainPair = namedtuple('TrainPair', ['content1', 'content2', 'label'])\n\ndef create_train_pairs(\n    df: pd.DataFrame\n    \n) -> List[TrainPair]:\n    \n    # To make sure we do not have mirror pairs such as (a, b, 1) (b, a, 1)\n    # pairs will contain desired pairs and _pairs will contain both desired and mirrored ones\n    pairs: List[TrainPair] = []\n    _pairs: Set[TrainPair] = set()\n        \n    authors = df['author'].unique()\n    \n    for author in authors:\n        \n        n_positive_pairs_per_author = len(df[df['author']==author])-1\n        n_negative_pairs_per_author = len(df[df['author']==author])-1\n        \n        \n        \n        positive_count = 0\n        while positive_count < n_positive_pairs_per_author:\n            content1, content2 = df[df['author'] == author].sample(2)['content'].values.tolist()\n            \n            if content1 != content2:\n            \n                pair = TrainPair(content1, content2, 1)\n                _pair = TrainPair(content2, content1, 1)\n\n                if pair in _pairs:\n                    continue\n                else:\n                    pairs.append(pair)\n                    _pairs.add(pair)\n                    _pairs.add(_pair)\n                    positive_count += 1\n                \n        negative_count = 0\n        while negative_count < n_negative_pairs_per_author:\n            content1 = df[df['author'] == author].sample(1)['content'].values[0]\n            content2 = df[df['author'] != author].sample(1)['content'].values[0]\n            \n                        \n            if content1 != content2:\n            \n\n                pair = TrainPair(content1, content2, 0)\n                _pair = TrainPair(content2, content1, 0)\n\n                if pair in _pairs:\n                    continue\n                else:\n                    pairs.append(pair)\n                    _pairs.add(pair)\n                    _pairs.add(_pair)\n                    negative_count += 1\n    \n    return list(pairs)","metadata":{"tags":[]},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_pairs = create_train_pairs(train_df)\neval_pairs = create_train_pairs(eval_df)","metadata":{"tags":[]},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Creating a full train pairs dataset\nfull_pairs = create_train_pairs(train_df_full)\nlen(full_pairs)","metadata":{"tags":[]},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":["656"]},"metadata":{}}]},{"cell_type":"markdown","source":"#### Cosine Similarities for matching authors","metadata":{"tags":[]}},{"cell_type":"markdown","source":"In the below code I perform some EDA to assess the cosine similarity values between vectors for sentences coming from the same authors and sentences coming from different authors. The process is not required for the prediction part of my code and the computations take some time to compile, especially without a GPU. On average, ignoring duplicates, for matching authors, considering that we have 37 distinct authors, each with roughly 10 pieces of text each, there would be ${10 \\choose 2}$ * 37 = 1665 combinations. While for non-matching authors, ignoring duplicates, this would increase to 68,265. It is hence being reproduced for analysis purposes only. ","metadata":{}},{"cell_type":"code","source":"# Group the DataFrame by 'author'\ngrouped = train_df_full.groupby('author')\n\n# Initialize an empty list to store pairs\nmatching_pairs = []\n\n# Iterate through each author group\nfor _, group in grouped:\n    # Get the content values for the current author group\n    content_values = group['content'].tolist()\n\n    # Create pairs of content values using combinations\n    content_pairs = list(combinations(content_values, 2))\n\n    # Append the pairs to the list\n    matching_pairs.extend(content_pairs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new list to store modified pairs\nmodified_matching_pairs = []\n\n# Iterate through the list of tuples\nfor pair in matching_pairs:\n    modified_pair = (f'query: {pair[0]}', f'passage: {pair[1]}')\n    modified_matching_pairs.append(modified_pair)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_duplicates_pairs(data):\n    '''\n    Removes duplicated pairs where (content1,content2) = (content2,content1)\n    Returns a set of unique pairs\n    '''\n    \n    seen_pairs = set()\n    unique_data = []\n\n    for pair in data:\n        content1 = pair[0]\n        content2 = pair[1]\n        \n\n        if (content1, content2) not in seen_pairs and (content2, content1) not in seen_pairs:\n            seen_pairs.add((content1, content2))\n            unique_data.append(pair)\n\n    return unique_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_matching_pairs = remove_duplicates_pairs(modified_matching_pairs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matching_scores = []\n\nfor i in range(len(modified_matching_pairs)):\n    corpus_embedding = model1.encode(modified_matching_pairs[i][0], convert_to_tensor=True, normalize_embeddings=True)\n    query_embedding = model1.encode(modified_matching_pairs[i][1], convert_to_tensor=True, normalize_embeddings=True)\n    hits = util.semantic_search(query_embedding, corpus_embedding, score_function=util.dot_score) # This function performs a cosine similarity search between a list of query embeddings and a list of corpus embeddings\n    hits = hits[0][0]\n    \n    matching_scores.append(hits['score'])\n        \nprint(f'OVERALL MAXIMUM SCORE: {max(matching_scores)}')\nprint(f'OVERALL MINIMUM SCORE: {min(matching_scores)}')\n    ","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the scores for future use\npd.Series(matching_scores).to_csv('matching_cossim.csv', index=False)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the scores in case of recurrent use\nmatching_scores = pd.read_csv('/home/kcini75/Notebooks/Tantus competition/top_score/matching_cossim.csv') # amend with your own saving location\nmatching_scores = [m for m in matching_scores['0']]","metadata":{"tags":[]},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"min(matching_scores), max(matching_scores)","metadata":{"tags":[]},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":["(0.7180267572402954, 0.964353322982788)"]},"metadata":{}}]},{"cell_type":"markdown","source":"#### Cosine Similarities for not matching authors","metadata":{"tags":[]}},{"cell_type":"code","source":"from itertools import product","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get unique authors\nunique_authors = train_df_full['author'].unique()\n\n# Initialize an empty list to store pairs\npairs_different_authors = []\n\n# Iterate through all combinations of unique authors\nfor author1, author2 in combinations(unique_authors, 2):\n    # Get content values for each author\n    content_values_author1 = train_df_full[train_df_full['author'] == author1]['content'].tolist()\n    content_values_author2 = train_df_full[train_df_full['author'] == author2]['content'].tolist()\n    \n    # Get author names\n    author_names = (author1, author2)\n    \n    # Create pairs of content values using product\n    content_pairs = list(product(content_values_author1, content_values_author2, [author_names]))\n        \n    \n    # Append the pairs to the list\n    pairs_different_authors.extend(content_pairs)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new list to store modified pairs\nmodified_non_matching_pairs = []\n\n# Iterate through the list of tuples\nfor pair in pairs_different_authors:\n    modified_pair = (f'query: {pair[0]}', f'passage: {pair[1]}',f'{pair[2][0]}', f'{pair[2][1]}')\n    modified_non_matching_pairs.append(modified_pair)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_non_matching_pairs = remove_duplicates_pairs(modified_non_matching_pairs)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dataframe for non matching pairs\n\nnon_matching_df = []\n\nfor query,passage,auth1, auth2 in modified_non_matching_pairs:\n    df_row = {'content1': None, 'content2': None, 'author1': None, 'author2': None}\n    df_row['content1'] = query\n    df_row['content2'] = passage\n    df_row['author1'] = auth1\n    df_row['author2'] = auth2\n    \n    non_matching_df.append(df_row)\n    \nnon_matching_df = pd.DataFrame(non_matching_df)\nnon_matching_df = non_matching_df.drop_duplicates()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"non_matching_df.head()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Careful ! this code takes long to execute without a GPU. It is not needed for the model but is here for EDA purposes. \nnon_matching_scores = []\n\nfor i in range(len(modified_non_matching_pairs)):\n    corpus_embedding = model1.encode(modified_non_matching_pairs[i][0], convert_to_tensor=True, normalize_embeddings=True)\n    query_embedding = model1.encode(modified_non_matching_pairs[i][1], convert_to_tensor=True, normalize_embeddings=True)\n    hits = util.semantic_search(query_embedding, corpus_embedding, score_function=util.dot_score) # This function performs a cosine similarity search between a list of query embeddings and a list of corpus embeddings\n    hits = hits[0][0]\n    \n    non_matching_scores.append(hits['score'])\n        \nprint(f'OVERALL MAXIMUM SCORE: {max(non_matching_scores)}')\nprint(f'OVERALL MINIMUM SCORE: {min(non_matching_scores)}')","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving scores for future use\npd.Series(non_matching_scores).to_csv('non_matching_cossim.csv', index=False)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading scores in case of recurrent use\nnon_matching_scores = pd.read_csv('/home/kcini75/Notebooks/Tantus competition/top_score/non_matching_cossim.csv') # amend with your own saving location\nnon_matching_scores = [m for m in non_matching_scores['0']]","metadata":{"tags":[]},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#### Plotting the scores histograms","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting first histogram\nplt.hist(matching_scores, label='Matching Scores', bins=100, alpha=.8, edgecolor='red' ,density=True)\n \n# plotting second histogram\nplt.hist(non_matching_scores, label='Non Matching scores', bins=100, alpha=0.7, edgecolor='yellow', density=True)\nplt.legend()\n \n# Showing the plot using plt.show()\nplt.show()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To remove some of the outliers only the values within 3 standard deviations are retained","metadata":{}},{"cell_type":"code","source":"# Extracting the values that are within 3 standard deviations from the mean\n\nmatching_array = np.array(matching_scores)\nnon_matching_array = np.array(non_matching_scores)\n\ndef get_bound(array,orig_list):\n    # Calculate the mean and standard deviation\n    mean =  np.mean(array)\n    std_dev = np.std(array)\n\n    # Calculate the lower and upper bounds for filtering\n    lower_bound = mean - 3 * std_dev\n    upper_bound = mean + 3 * std_dev\n\n    # Filter out values within 2 standard deviations from the mean\n    filtered_values = [value for value in orig_list if lower_bound <= value <= upper_bound]\n    \n    return filtered_values","metadata":{"tags":[]},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"filtered_matching = get_bound(matching_array, matching_scores)\nfiltered_non_matching = get_bound(non_matching_array, non_matching_scores)","metadata":{"tags":[]},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Plotting the histogrames again after filtering","metadata":{}},{"cell_type":"code","source":"# plotting first histogram\nplt.hist(filtered_matching, label='Filtered Matching Scores', bins=100, alpha=.8, edgecolor='red' ,density=True)\n \n# plotting second histogram\nplt.hist(filtered_non_matching, label='Filtered Non Matching scores', bins=100, alpha=0.7, edgecolor='yellow', density=True)\nplt.legend()\n \n# Showing the plot using plt.show()\nplt.show()","metadata":{"tags":[]},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABbj0lEQVR4nO3deXhU5fn/8ffMZJbsgRCyaFgVZBVBobiBSgu4xyqIVFBcaguoRa1iK5tWtNaKC0K1BWqrpfotIr+qqNBSK6AI1q0qZQmbZAIEQvbMdn5/RIYMZM9MZsnndV1zXTnr3Ccnydx5znM/j8kwDAMRERGRCGYOdwAiIiIijVHCIiIiIhFPCYuIiIhEPCUsIiIiEvGUsIiIiEjEU8IiIiIiEU8Ji4iIiEQ8JSwiIiIS8eLCHUAw+Hw+9u/fT3JyMiaTKdzhiIiISBMYhkFpaSk5OTmYzQ23ocREwrJ//35yc3PDHYaIiIi0wN69ezn11FMb3CcmEpbk5GSg5oJTUlLCHI2IiIg0RUlJCbm5uf7P8YbERMJy7DFQSkqKEhYREZEo05TuHOp0KyIiIhFPCYuIiIhEPCUsIiIiEvFiog+LiEQ3wzDweDx4vd5whyIiQWaxWIiLi2v1sCNKWEQkrFwuFwUFBVRUVIQ7FBEJkYSEBLKzs7HZbC0+hxIWEQkbn89Hfn4+FouFnJwcbDabBn8UiSGGYeByuTh48CD5+fmcfvrpjQ4QVx8lLCISNi6XC5/PR25uLgkJCeEOR0RCID4+HqvVyu7du3G5XDgcjhadR51uRSTsWvofl4hEh2D8juuvhIiIiEQ8PRISkcjjdEJxcdu9X1oaZGUF5VQjR45k0KBBLFiwAIBu3bpx9913c/fddwfl/MFgMpl4/fXXufrqq8MdSoMai3PdunVcdNFFHDlyhLS0tDaNTdpesxOW999/nyeeeIItW7ZQUFBw0g9TfR3mfv3rX3PffffVuW3OnDnMnTs3YF3v3r355ptvmhueiEQ7p5PyK/OoKi1vs7d0JCeSuOr1JictN910E3/84x9PWr9t2zZWrFiB1Wqt99hoSBaOXd+Pf/xjFi9eHLBt6tSpPP/880yePJlly5Y16Xy7du2ie/fu/Oc//2HQoEFBi/Pcc8+loKCA1NTUoJ2zPi+++CLPPfccO3bsIC4uju7duzNu3DhmzpwZ8veWGs1OWMrLyznzzDOZMmUK11xzzUnbCwoKApbffvttbrnlFn74wx82eN5+/fqxZs2a44HFqfFHpF0qLqaqtJxnR06iMD075G+XWVTA9HUvkVhc3KxWljFjxrB06dKAdRkZGVgsliBHWDe3291gYtRaubm5LF++nKeeeor4+HgAqqqqeOWVV+jSpUvI3rc5bDYbWUFqGWvIkiVLuPvuu3nmmWcYMWIE1dXVfP7553z55Zche0+Xy9WqEuBY1Ow+LGPHjuWRRx4hLy+vzu1ZWVkBrzfeeIOLLrqIHj16NHjeuLi4gOM6derU3NBEJIYUpmezL7NryF8tTYrsdvtJf+8sFgsjR46s9/FPt27dAMjLy8NkMvmXAd544w0GDx6Mw+GgR48ezJ07F4/H499uMplYtGgRV155JYmJifzqV79q0nHbtm3jwgsvxOFw0LdvX957770mXd/gwYPJzc1lxYoV/nUrVqygS5cunHXWWQH7rl69mvPPP5+0tDTS09O5/PLL2bFjh3979+7dATjrrLMwmUyMHDnSv23JkiX069cPu91OdnY206ZNCzj3oUOHyMvLIyEhgdNPP51Vq1b5t61btw6TyUTxd48Ply1bRlpaGu+88w59+vQhKSmJMWPGBPwj7fF4uPPOO/2x3n///UyePLnBFq9Vq1Yxbtw4brnlFk477TT69evHhAkT/PegKdeyZ88errrqKpKSkkhJSWHcuHEUFhb6t8+ZM4dBgwbx+9//nu7du/sraYqLi7n11lvJyMggJSWFiy++mM8++8x/3GeffcZFF11EcnIyKSkpDBkyhM2bN9d7LdEspJ1uCwsLefPNN7nlllsa3Xfbtm3k5OTQo0cPJk6cyJ49e+rdt7q6mpKSkoCXiEQ5txsqK6GqCgyj5hVjPv74YwCWLl1KQUGBf/nf//43kyZN4q677uKrr77id7/7HcuWLTvpA3HOnDnk5eXxxRdfMGXKlEaP8/l8XHPNNdhsNj766CMWL17M/fff3+R4p0yZEtCKtGTJEm6++eaT9isvL2fGjBls3ryZtWvXYjabycvLw+fzAbBp0yYA1qxZQ0FBgT8JWrRoEVOnTuX222/niy++YNWqVZx22mkB5547dy7jxo3j888/59JLL2XixIkcPny43pgrKir4zW9+w5/+9Cfef/999uzZw7333uvf/vjjj/Pyyy+zdOlS1q9fT0lJCStXrmzw+5CVlcWHH37I7t27692noWvx+XxcddVVHD58mH/961+899577Ny5k/HjxwecY/v27fztb39jxYoVfPrppwBcd911HDhwgLfffpstW7YwePBgLrnkEv/3YOLEiZx66ql8/PHHbNmyhQceeCCkLW/hFNLnLn/84x9JTk6u89FRbcOGDWPZsmX07t2bgoIC5s6dywUXXMCXX35JcnLySfvPnz//pD4vIhLF3G68+fkYXh/s2QseD4aruiZpidCB5P7+97+TlJTkXx47diyvvfZag8dkZGQAkJaWFvAoY+7cuTzwwANMnjwZgB49evDwww/z85//nNmzZ/v3u+GGGwIShilTpjR43Jo1a/jmm2945513yMnJAeDRRx9l7NixTbrGH/3oR8ycOdP/Qb1+/XqWL1/OunXrAvY78ZH/kiVLyMjI4KuvvqJ///7+605PTw+47kceeYR77rmHu+66y7/unHPOCTjXTTfdxIQJE/yxP/PMM2zatIkxY8bUGbPb7Wbx4sX07NkTgGnTpjFv3jz/9meffZaZM2f6nxI899xzvPXWWw1+H2bPns0111xDt27d6NWrF8OHD+fSSy/l2muv9ZfrNnQta9eu5YsvviA/P5/c3FwAXnrpJfr168fHH3/s38/lcvHSSy/5v18ffPABmzZt4sCBA9jtdgB+85vfsHLlSv7v//6P22+/nT179nDfffdxxhlnAHD66ac3eC3RLKQJy5IlS5g4cWKjg8TU/uUZOHAgw4YNo2vXrrz66qt1ts7MnDmTGTNm+JdLSkr8PwQiEoW8XgyvjwPJ6RippVhNZjCI6ITloosuYtGiRf7lxMTEFp/rs88+Y/369QEtKl6vl6qqKioqKvyD6p199tnNOu7rr78mNzfXn6wADB8+vMlxZWRkcNlll7Fs2TIMw+Cyyy6r83H9tm3bmDVrFh999BGHDh3yt6zs2bOH/v3713nuAwcOsH//fi655JIGYxg4cKD/68TERFJSUjhw4EC9+yckJPiTFYDs7Gz//kePHqWwsJChQ4f6t1ssFoYMGeKPuS7Z2dls3LiRL7/8kvfff58NGzYwefJkfv/737N69WoOHTrU4LUcuw+1P6f69u1LWloaX3/9tT9h6dq1qz9ZgZr7W1ZWRnp6esD5Kisr/Y/cZsyYwa233sqf/vQnRo0axXXXXRdw/bEkZAnLv//9b7Zu3cpf//rXZh+blpZGr1692L59e53b7Xa7P9sUkdjhjrNiWKzERWiSUltiYuJJjy9aqqysjLlz59bZGl37H74Tk6KmHtcaU6ZM8ffFWLhwYZ37XHHFFXTt2pUXX3yRnJwcfD4f/fv3x+Vy1XveYx15G3Pi4w2TydRgclHX/kaQHi/279+f/v3789Of/pQ77riDCy64gH/9618nJZItVdf9zc7OPqlFC/CXcc+ZM4cbbriBN998k7fffpvZs2ezfPnyevuZRrOQJSx/+MMfGDJkCGeeeWazjy0rK2PHjh3ceOONIYhMRCR8rFbrSbNSDx48mK1btzY7AWrsuD59+rB3714KCgrIzq7pXPzhhx826z3GjBmDy+XCZDIxevTok7YXFRWxdetWXnzxRS644AKg5lFGbceqXWpfd3JyMt26dWPt2rVcdNFFzYqppVJTU8nMzOTjjz/mwgsv9Mf0ySefNLvcum/fvkBN/53GruXYfdi7d6+/leWrr76iuLjYf566DB48GKfTSVxcXEAH7RP16tWLXr168bOf/YwJEyawdOlSJSxQk0zUbvnIz8/n008/pWPHjv5St5KSEl577TWefPLJOs9xySWXkJeX58/a7733Xn+Gvn//fmbPno3FYvE/txQRiRXHPtjOO+887HY7HTp0YNasWVx++eV06dLF3y/is88+48svv+SRRx6p91yNHTdq1Ch69erF5MmTeeKJJygpKeEXv/hFs+K1WCx8/fXX/q9P1KFDB9LT03nhhRfIzs5mz549PPDAAwH7dO7cmfj4eFavXs2pp56Kw+EgNTWVOXPmcMcdd9C5c2fGjh1LaWkp69evZ/r06c2KsTmmT5/O/PnzOe200zjjjDN49tlnOXLkSIOTbv7kJz8hJyeHiy++mFNPPZWCggIeeeQRMjIy/I/YGrqWUaNGMWDAACZOnMiCBQvweDz89Kc/ZcSIEQ22zowaNYrhw4dz9dVX8+tf/5pevXqxf/9+3nzzTfLy8ujXrx/33Xcf1157Ld27d2ffvn18/PHHjQ4jEq2anbBs3rw5IIM81pek9iBCy5cvxzCMehOOHTt2cOjQIf/yvn37mDBhAkVFRWRkZHD++efz4YcfBjzLE5H2JfOwE5PNBiGeZyizqKDxnYLoySefZMaMGbz44ouccsop7Nq1i9GjR/P3v/+defPm8fjjj2O1WjnjjDO49dZbGzxXY8eZzWZef/11brnlFoYOHUq3bt145pln6u2wWp+UlJR6t5nNZpYvX86dd95J//796d27N88880xA6XJcXBzPPPMM8+bNY9asWVxwwQWsW7eOyZMnU1VVxVNPPcW9995Lp06duPbaa5sVW3Pdf//9OJ1OJk2ahMVi4fbbb2f06NENjp8zatQolixZwqJFiygqKqJTp04MHz6ctWvX+vuXNHQtJpOJN954g+nTp3PhhRdiNpsZM2YMzz77bIOxmkwm3nrrLX7xi19w8803c/DgQbKysrjwwgvJzMzEYrFQVFTEpEmTKCwspFOnTlxzzTUxW5RiMoL1cC+MSkpKSE1N5ejRow3+YolIZKmqqiI/P5/u2dnE7fuWbztk4T18hA6TJuArLYO4uDbpdNvckW4ldvh8Pvr06cO4ceN4+OGHwx1OzPL/rtcaYwaa9/mt4WRFJKJ4O2dStuSPZO/dQVyXXAhS59EGBXEuIYlsu3fv5t133/WPWPvcc8+Rn5/PDTfcEO7QpBFKWEQk4vg6Z4LVgJ49oInVJCJNYTabWbZsGffeey+GYdC/f3/WrFlDnz59wh2aNEIJi4iItBu5ubmsX78+3GFIC4S2N5uIiIhIEChhERERkYinhEVEREQinhIWERERiXhKWERERCTiKWERERGRiKeERUQijtl8CGx7wLQT2NEGr4NBi33kyJHcfffd/uVu3bqxYMGCoJ0/GEwmEytXrgx3GBGvse/TunXrMJlMFBcXt1lM7ZnGYRGRiGIxHaJTwh1YzAegyg6u0A/Njy0dHC8DTZu/7KabbuKPf/zjSeu3bdvGihUrsFqt9R5rMpl4/fXXufrqq1sYbOgdu7758+cHTGS4cuVK8vLyCPWMLsfe/8c//jGLFy8O2DZ16lSef/75gPnrGrNr1y66d+/Of/7zn2bPytyQc889l4KCAlJTU4N2TqmfEhYRiShmcwlmzxGMj5IweTtAA5PSBUVCBQwtAkcJTU1YAMaMGcPSpUsD1mVkZDQ4iV4wud3uBhOj1nI4HDz++OP8+Mc/pkOHDiF7n/rk5uayfPlynnrqKeK/G+24qqqKV155hS5durR5PHWx2WxkxeCUDqH+2WopPRISkchU7oCypNC/KhJaFJ7dbicrKyvgZbFYTnokVFu3bt0AyMvLw2Qy+ZcB3njjDQYPHozD4aBHjx7MnTsXj8fj324ymVi0aBFXXnkliYmJ/OpXv2rScdu2bePCCy/E4XDQt29f3nvvvSZd36hRo8jKymL+/PkN7ve3v/2Nfv36Ybfb6datG08++eRJ1/zoo48yZcoUkpOT6dKlCy+88EKj7z948GByc3NZsWKFf92KFSvo0qULZ511VsC+q1ev5vzzzyctLY309HQuv/xyduzY4d/evXt3AM466yxMJlPATNJLlizxx5+dnc20adMCzn3o0CHy8vJISEjg9NNPZ9WqVf5tJz4SWrZsGWlpabzzzjv06dOHpKQkxowZQ0HB8RnBPR4Pd955pz/W+++/n8mTJzfY4rZ7926uuOIKOnToQGJiIv369eOtt97yb//vf//L5ZdfTkpKCsnJyVxwwQX+6/f5fMybN49TTz0Vu93OoEGDWL16tf/YXbt2YTKZ+Otf/8qIESNwOBy8/PLLAPz+97+nT58+OBwOzjjjDJ5//nn/cS6Xi2nTppGdnY3D4aBr166N/qy0lhIWEZE28vHHHwOwdOlSCgoK/Mv//ve/mTRpEnfddRdfffUVv/vd71i2bJk/KTlmzpw55OXl8cUXXzBlypRGj/P5fFxzzTXYbDY++ugjFi9ezP3339+kWC0WC48++ijPPvss+/btq3OfLVu2MG7cOK6//nq++OIL5syZw0MPPXTSo5onn3ySs88+m//85z/89Kc/5Sc/+Qlbt25tNIYpU6YEtGItWbKEm2+++aT9ysvLmTFjBps3b2bt2rWYzWby8vLw+XwAbNq0CYA1a9ZQUFDgT4IWLVrE1KlTuf322/niiy9YtWoVp512WsC5586dy7hx4/j888+59NJLmThxIocPH6435oqKCn7zm9/wpz/9iffff589e/Zw7733+rc//vjjvPzyyyxdupT169dTUlLSaH+iqVOnUl1dzfvvv88XX3zB448/TlJSEgDffvstF154IXa7nX/84x9s2bKFKVOm+JPWp59+mieffJLf/OY3fP7554wePZorr7ySbdu2BbzHAw88wF133cXXX3/N6NGjefnll5k1axa/+tWv+Prrr3n00Ud56KGH/I9Cn3nmGVatWsWrr77K1q1befnllwMS8JAwYsDRo0cNwDh69Gi4QxGRZqisrDS++uoro/LIEcP9xZfGrn2HjPyDnxpVh840vK9caBgv/dAwXh4X2tcblxrG0cGGYWxvctyTJ082LBaLkZiY6H9de+21hmEYxogRI4y77rrLv2/Xrl2Np556yr8MGK+//nrA+S655BLj0UcfDVj3pz/9ycjOzg447u67727Wce+8844RFxdnfPvtt/7tb7/9dp0xnHh9V111lWEYhvG9733PmDJlimEYhvH6668btT82brjhBuP73/9+wLH33Xef0bdv34Dr/9GPfuRf9vl8RufOnY1FixY1+v4HDhww7Ha7sWvXLmPXrl2Gw+EwDh48aFx11VXG5MmT6z3+4MGDBmB88cUXhmEYRn5+vgEY//nPfwL2y8nJMX7xi1/Uex7A+OUvf+lfLisrMwDj7bffNgzDMP75z38agHHkyBHDMAxj6dKlBmBs3378Z2nhwoVGZmamfzkzM9N44okn/Msej8fo0qWL//tdlwEDBhhz5sypc9vMmTON7t27Gy6Xq87tOTk5xq9+9auAdeecc47x05/+1DCM49+bBQsWBOzTs2dP45VXXglY9/DDDxvDhw83DMMwpk+fblx88cWGz+erN+7a/L/rlZUB65vz+a0+LCIiLXDRRRexaNEi/3JiYmKLz/XZZ5+xfv36gBYVr9dLVVUVFRUVJCTUPLY6++yzm3Xc119/TW5uLjk5Of7tw4cPb1Zsjz/+OBdffHFAK8ExX3/9NVdddVXAuvPOO48FCxbg9Xr9/XkGDhzo324ymcjKyuLAgQONvndGRgaXXXYZy5YtwzAMLrvsMjp16nTSftu2bWPWrFl89NFHHDp0yN+ysmfPHvr371/nuQ8cOMD+/fu55JJLGoyhduyJiYmkpKQ0GHtCQgI9e/b0L2dnZ/v3P3r0KIWFhQwdOtS/3WKxMGTIEH/Mdbnzzjv5yU9+wrvvvsuoUaP44Q9/6I/r008/5YILLqizz0lJSQn79+/nvPPOC1h/3nnn8dlnnwWsq/2zVV5ezo4dO7jlllu47bbb/Os9Ho+/g/FNN93E97//fXr37s2YMWO4/PLL+cEPflDvNQSDEhYRkRZITEw86fFBS5WVlTF37lyuueaak7Y5HI6A92zJca1x4YUXMnr0aGbOnMlNN93UonOc+GFqMpka/ICubcqUKf5+JQsXLqxznyuuuIKuXbvy4osvkpOTg8/no3///rhcrnrPe6wjb7Bjr2t/o5VVVbfeeiujR4/mzTff5N1332X+/Pk8+eSTTJ8+vcnX0ZjaP1tlZWUAvPjiiwwbNixgv2NJ6ODBg8nPz+ftt99mzZo1jBs3jlGjRvF///d/QYmnLkpYRETakNVqxev1BqwbPHgwW7dubXYC1Nhxffr0Ye/evRQUFJCdnQ3Ahx9+2OyYH3vsMQYNGkTv3r1POv/69esD1q1fv55evXoFrVpqzJgxuFwuTCYTo0ePPml7UVERW7du5cUXX+SCCy4A4IMPPgjYx2azAQR835OTk+nWrRtr167loosuCkqsjUlNTSUzM5OPP/6YCy+80B/TJ5980mi5dW5uLnfccQd33HEHM2fO5MUXX2T69OkMHDiQP/7xj3VW9qSkpJCTk8P69esZMWKEf/369esDWnlOlJmZSU5ODjt37mTixIn17peSksL48eMZP3481157LWPGjOHw4cN07NixCd+N5lPCIiLh4XTC4cPg8YDbDSEe2yNSHPuQPO+887Db7XTo0IFZs2Zx+eWX06VLF6699lrMZjOfffYZX375JY888ki952rsuFGjRtGrVy8mT57ME088QUlJCb/4xS+aHfOAAQOYOHEizzzzTMD6e+65h3POOYeHH36Y8ePHs3HjRp577rmAapLWslgsfP311/6vT9ShQwfS09N54YUXyM7OZs+ePQFjxwB07tyZ+Ph4Vq9ezamnnorD4SA1NZU5c+Zwxx130LlzZ8aOHUtpaSnr169n+vTpQYv/RNOnT2f+/PmcdtppnHHGGTz77LMcOXIEk6n+8Ybuvvtuxo4dS69evThy5Aj//Oc/6dOnDwDTpk3j2Wef5frrr2fmzJmkpqby4YcfMnToUHr37s19993H7Nmz6dmzJ4MGDWLp0qV8+umn/kqg+sydO5c777yT1NRUxowZQ3V1NZs3b+bIkSPMmDGD3/72t2RnZ3PWWWdhNpt57bXXyMrKIi0tLZjfrgCqEhKRtud0Un5lHkem3Y334EE8BQUYHk9g0pJYBUlloX8lVLTppT/55JO899575Obm+stzR48ezd///nfeffddzjnnHL73ve/x1FNP0bVr1wbP1dhxZrOZ119/ncrKSoYOHcqtt956UuVRU82bN++kRyGDBw/m1VdfZfny5fTv359Zs2Yxb968Fj86qk9KSgopKSl1bjObzSxfvpwtW7bQv39/fvazn/HEE08E7BMXF8czzzzD7373O3Jycvz9biZPnsyCBQt4/vnn6devH5dffvlJ1TPBdv/99zNhwgQmTZrE8OHDSUpKYvTo0Q0+wvN6vUydOpU+ffowZswYevXq5U8K09PT+cc//kFZWRkjRoxgyJAhvPjii/7WljvvvJMZM2Zwzz33MGDAAFavXs2qVas4/fTTG4zz1ltv5fe//z1Lly5lwIABjBgxgmXLlvlLxJOTk/n1r3/N2WefzTnnnMOuXbt46623MJtDl1aYjNY+XIsAJSUlpKamcvTo0Xp/qEUkgnzzDUV541h61R1876qhdE/vROfyYvZ3OhWvvZRs+xQcVQcw2e1gjryRbkWCxefz0adPH8aNG8fDDz8c7nBCpqqqivz8fLp37x6QnDXn81uPhEQi1kGg5LuvU4jFD9NDaRl4zRa8tZr6vUYnDlUsJrt0J3FdukCQOo82LDa/vxJ5du/ezbvvvsuIESOorq7mueeeIz8/nxtuuCHcoUU8JSwiEekgVE0EV1HNYjtrAfD5OoHLA0YPIDhVECKRwGw2s2zZMu69914Mw6B///6sWbPG3ydF6qeERSSiHGtV2Q2uQtj0XW/7Fsx1IyKRJzc396TKKmkaJSwiEaNWq4qpGnx7oaIzYOP4oyERkfZJVUIiEaOkJlnZlAKfJ4HhBTyNHiUi0h6ohUUk0lQkAA0V79XujAvR3GHUwMCg4asVkegXjIJkJSwiUeWEzrgQ1R1yK6u8eH0Gbo873KGISAhVVNSMd1TXnEdNpYRFJKrUemxUkVAz6FkUd8h1e3x8UuAimSJS7BY8HhdekwmP10WVz0dcdTU0MAKoiEQ2wzCoqKjgwIEDpKWltWrKBiUsImFXqzKoqX1WKhKgLOm7hejukPvvbz3kHNxDQk4CxZUevHFWLD4vlRVHsWBAK/4jE5HIkJaWRlZWVqvOoYRFJKzqqAyic7iDalMGsO0/uxk1+xn+9NP5HMjpTuah/dz17ot0eG4BfDcUuIhEJ6vVGpTJMJWwiIRVrUc88ZXQt/1WBpkrKykpdXGo0sBR5sJW4MRhNrfRSLciEumUsIhEgkYrg0RE2jclLCLRzuSmpv8LRHOJs4hIQ5SwiESDgKSk1iMjWzWYdkPJXYAtqkucRUQaooRFJNLVTkpMRmDH3DgPuL2wJQlwRHWJs4hIQ5SwiES62klJvFF3x9wKB5BAtJc4i4jURwmLSLSocKCOuSLSXilhEZHo5HRCcfHx5bQ0aM7AVK09XkTaVLNna37//fe54ooryMnJwWQysXLlyoDtN910EyaTKeA1ZsyYRs+7cOFCunXrhsPhYNiwYWzatKm5oYmIv3PuDmpG0I1RTiflV+ZRlDfO/yq/Mq8mCWmL40WkzTW7haW8vJwzzzyTKVOmcM0119S5z5gxY1i6dKl/2W63N3jOv/71r8yYMYPFixczbNgwFixYwOjRo9m6dSudO7evUT9FWqw9VQwVF1NVWs6zIydRmJ5NZlEB09e9RGJxcdNaSVp7vIi0uWYnLGPHjmXs2LEN7mO325s1Z8Bvf/tbbrvtNm6++WYAFi9ezJtvvsmSJUt44IEHmhuiSBRowfxBjWmHFUOF6dnsy+watuNFpO00+5FQU6xbt47OnTvTu3dvfvKTn1BUVFTvvi6Xiy1btjBq1KjjQZnNjBo1io0bN4YiPJEw+27+oJJxUHon+HYBruCdvsLx3ci5IiKxI+idbseMGcM111xD9+7d2bFjBw8++CBjx45l48aNdU5+dOjQIbxeL5mZmQHrMzMz+eabb+p8j+rqaqqrq/3LJSUq5ZRoovmDRESaK+gJy/XXX+//esCAAQwcOJCePXuybt06LrnkkqC8x/z585k7d25QziUSNpo/KKhMHjfs3Hl8hap+RGJKSB4J1dajRw86derE9u3b69zeqVMnLBYLhYWFAesLCwvr7Qczc+ZMjh496n/t3bs36HGLSPRIKSvG4nRSdOc9qvoRiVEhT1j27dtHUVER2dnZdW632WwMGTKEtWvX+tf5fD7Wrl3L8OHD6zzGbreTkpIS8BKRE7SXEmcgvqoCl9nCsyNu5Jc/vJ9nR06iqrQ8cJwVEYlqzX4kVFZWFtBakp+fz6effkrHjh3p2LEjc+fO5Yc//CFZWVns2LGDn//855x22mmMHj3af8wll1xCXl4e06ZNA2DGjBlMnjyZs88+m6FDh7JgwQLKy8v9VUMi0kztqcS5lsKOWar6EYlRzU5YNm/ezEUXXeRfnjFjBgCTJ09m0aJFfP755/zxj3+kuLiYnJwcfvCDH/Dwww8HjMWyY8cODh065F8eP348Bw8eZNasWTidTgYNGsTq1atP6ogrIk3UDkucRSS2NTthGTlyJIZRf0fBd955p9Fz7Nq166R106ZN87e4iMSeY+OuQFDHXmnMsUkRTUXfvS9ACkpcRCTaaC4hkZD7btwV13fjEZmqwbcXaKNRnNvp4yERiS1KWESCqnZLiguwAbvBVQibOtaUMqcXte3YK3o8JCIxQAmLSNDUakkxucGyHzyngMlb06JS0RnKkiChPDzhHXs8hAZaFJHoo4RFJGhOHMG2CrYkQLyh0WxFRFpJCYtIsNUewbbCgUazFRFpvZAPHCciIiLSWkpYREREJOIpYREREZGIpz4sIq12rJS5DQeEExFpZ5SwiLRK7VLmNh4QTkSkHdEjIZFWqVXK/HkSGCpfFhEJBbWwiARD7VJmEREJOiUsIu1a7akEQBMjikikUsIi0m6dMCkjaGJEEYlYSlhE2q1a/W8qEiChIqYmRjR53LBz5/EVaWmQldXyEzqdUFwcvPOJSLMoYRFp7yoSaiZlBGJlYsSUsmIsTidFd94DVisAjuREEle93rIkw+mk/Mo8qkqPT1zZqvOJSLMpYRFpb0xuasaMgVitaIqvqsBltrBwxI0UZncls6iA6eteIrG4uGUJRnExVaXlPDtyEoXp2a0/n4g0mxIWkfbEVg2m3VByF5iMmB83prBjFvsyuwbvfOnZQT2fiDSdEhaR9iTOA24vbEmCeAP6atwYEYkOSlhE2qMKBxo3RkSiiUa6FRERkYinFhYRkRYIetm0iDRICYtIk9UeFVYjwrZnQS+bFpFGKWERaZITRoW1JYPj10AZ6rTa/gS9bFpEGqWERaRJao0Ka3XBkP9AyS3tojRY6hfssmkRqZ8SFpHmqEiABEOlwSIibUwJi0hLqTRYRKTNKGERkeMChu1vpGOxJgMUkTakhEVEatQeth8b2NLB8TJ1Ji2aDFBE2pgSFhGpUXvYfhwwtAgcJdSZsGgyQBFpY0pYRCRQhQNI4PiYM/XTZIAi0lY0NL+IiIhEPCUsIiIiEvGUsIiIiEjEUx8WERE0maFIpFPCIiLtniYzFIl8SlhEpN3TZIYikU8Ji4jIdzSZoUjkUsIiUq+DHB+LZDea4FBEJHyUsIjU6SBUTQRXUc2iqRp8e4HOYY2qTTVnXiERkRBrdlnz+++/zxVXXEFOTg4mk4mVK1f6t7ndbu6//34GDBhAYmIiOTk5TJo0if379zd4zjlz5mAymQJeZ5xxRrMvRiR4SmqSlU0psC4LPk8Cw0u7aWWpPa9Qybia5I2D4Y5KRNqxZics5eXlnHnmmSxcuPCkbRUVFXzyySc89NBDfPLJJ6xYsYKtW7dy5ZVXNnrefv36UVBQ4H998MEHzQ1NJPgqEqAsCSod4Y6kbR2bV2hTUk3S5iqiKUP1i4iESrMfCY0dO5axY8fWuS01NZX33nsvYN1zzz3H0KFD2bNnD126dKk/kLg4stQbXySyNGNeIRGRUAr5SLdHjx7FZDKRlpbW4H7btm0jJyeHHj16MHHiRPbs2VPvvtXV1ZSUlAS8RCSE/P1ZdqBHQyISDiFNWKqqqrj//vuZMGECKSkp9e43bNgwli1bxurVq1m0aBH5+flccMEFlJaW1rn//PnzSU1N9b9yc3NDdQkiUld/FsvhcEclIu1MyBIWt9vNuHHjMAyDRYsWNbjv2LFjue666xg4cCCjR4/mrbfeori4mFdffbXO/WfOnMnRo0f9r71794biEkQE6u7PYi4Ld1Qi0s6EpKz5WLKye/du/vGPfzTYulKXtLQ0evXqxfbt2+vcbrfbsdvtwQhV5ATHxl7RuCsnUX8WEQmjoLewHEtWtm3bxpo1a0hPT2/2OcrKytixYwfZ2dnBDk+kAd+NvVIyDkrvBN8uwBXuoEREhBYkLGVlZXz66ad8+umnAOTn5/Ppp5+yZ88e3G431157LZs3b+bll1/G6/XidDpxOp24XMf/8F9yySU899xz/uV7772Xf/3rX+zatYsNGzaQl5eHxWJhwoQJrb9CkSarNfZKext3RUQkwjX7kdDmzZu56KKL/MszZswAYPLkycyZM4dVq1YBMGjQoIDj/vnPfzJy5EgAduzYwaFDh/zb9u3bx4QJEygqKiIjI4Pzzz+fDz/8kIwMjawpYVCRABjhjiJymdwQtx9zbjVJCXo8JCJto9kJy8iRIzGM+v+YN7TtmF27dgUsL1++vLlhiEg4HKsYSniU5HnfMiXpeR7Z+Gi4oxKRdiDk47CISAw5VjH0USLGv+0kxpWTYKsId1Qi0g4oYRGR5itzYBzRnw8RaTuarVlEQsPphOLi48tpadCa6Tdqn2/nTvB6WxGciEQbJSwiEnxOJ+VX5lFVWu5f5UhOJHHV6y1LWk44n7m6CuNwMbhVxSXSXihhEZHgKy6mqrScZ0dOojA9m8yiAqave4nE4uKWJSwnnK/f9s8Y//YS8KmVRaS9UMIiotFtQ6YwPZt9mV2Dfr7MQ/uDdk4RiQ5KWKSd+250W1cRmKrBtxfoHO6gRETkBOrmL+2cRrcVEYkGamERAY1uKyIS4dTCIiIiIhFPCYuIiIhEPD0SknbkWDUQQAqgyTVFRKKFEhZpJ2pVAwHY0sHxcnhDEhGRJlPCIu1ErWoggKFF4Chp+BAREYkYSlikfalI+O4LJSsiItFEnW5FREQk4ilhERERkYinhEVEREQinhIWERERiXjqdCsiLWa2eMlIdmLp6MXUQXMwiUjoKGGR9snkBnZ/t6AP2hZJ9JHe8SA/PutpTH0hadBBsBwOd1QiEqOUsEj7Y6sG024ouQtMBvj2Ap3DHVX0sRtYvD7cGxMxVRmY+/rAXBbuqEQkRilhkfYnzgNuL2xJgngD+nppl60sbjcYPqiogrIy6OBu2WlK7ZgqGp/p2uRxw86dNQs7d4LXG9T9wy0gXoC0NMjKCls8IrFGCYu0XxUOoPEP2pjkduPZ/g2WQS7c//sf7LViLnMTNyw034+UsmIsTidFd94DVivm6iqMw8XgrjtRbO7+4XZivACO5EQSV72upEUkSJSwiLRHbi8+nw+fxcLe9Bw8lXa6+3YQqgQuvqoCl9nCwhE3UpjdlX7bP2P820vAV3erSXP3D7cT480sKmD6updILC5WwiISJEpYJMYdm6F5N+3ysU+jTLji7Lit9jZ5t8KOWezL7Ermof0h2T/cjsUrIsGnhEViWK0Zmk3V6lwrIhLFNHCcxLBaMzR/ngRGO+1cKyISA9TCIrGvIoF227lW/CKu6sjphOLi48uqKhJpkBIWEYl5EVd15HRSfmUeVaXl/lWqKhJpmBIWEYl5EVd1VFxMVWk5z46cRGF6tqqKRJpACYvEIFUGSd0ireqoMD1bVUUiTaSERWKMKoPCJs6AuP3ADrDu0WSIIhJUSlgkxtSqDIqvbL/D7rcxS7wbc64LzI9CSTIkV5P0yF6SPiwJd2giEiOUsEhsUmVQmzLbfJh8wMeJ4MsCUxHmDB8OR2W4QxORGKGERUSaxu2Gyu8mTKyuos6EsMwBviQwlUNGm0cYUU6aDNHlAput5utIKKsWiTJKWESkcYaB9+uteB0erGe78OTvArsetdXnxDJqk8eN9eABXJ2zwGIJf1m1SBRSwiIiTWDg9flwpmaQZankUFIH0t2FmMIdVoSqr4x64QUTI6OsWiQKaWh+EWkyt8WGYTLhsVjDHUpUOFZGfSgto85lEWm6Zics77//PldccQU5OTmYTCZWrlwZsN0wDGbNmkV2djbx8fGMGjWKbdu2NXrehQsX0q1bNxwOB8OGDWPTpk3NDU1ERERiVLMTlvLycs4880wWLlxY5/Zf//rXPPPMMyxevJiPPvqIxMRERo8eTVVVVb3n/Otf/8qMGTOYPXs2n3zyCWeeeSajR4/mwIEDzQ1PREREYlCzE5axY8fyyCOPkJeXd9I2wzBYsGABv/zlL7nqqqsYOHAgL730Evv37z+pJaa23/72t9x2223cfPPN9O3bl8WLF5OQkMCSJUuaG55I++X+roKnogoqK8Fo67Juo6Z6qKwMqqrC8P4iEsuC2oclPz8fp9PJqFGj/OtSU1MZNmwYGzdurPMYl8vFli1bAo4xm82MGjWq3mOqq6spKSkJeIm0a243nq+/wah24frf/3Bt/R+Gq7omiWkDFp8HDHDt2oXr4y24tv4PPB5wq1OpiARHUBMWp9MJQGZmZsD6zMxM/7YTHTp0CK/X26xj5s+fT2pqqv+Vm5sbhOgleh0Ednz3aqfzB7m9+Hw+3BYLe9NzcKZm1AyT0kYJg9nnwwCcyRl8k92TwtRONaO0GEpYRCQ4orKseebMmcyYMcO/XFJSoqSl3ao1dxBo/iBMuOLsYAnP4xi31UaVPQG3xR6W9xeR2BXUhCXru2nRCwsLyc7O9q8vLCxk0KBBdR7TqVMnLBYLhYWFAesLCwv95zuR3W7HbtcfRIGAuYMqEiC9SPMHiYjEoKA+EurevTtZWVmsXbvWv66kpISPPvqI4cOH13mMzWZjyJAhAcf4fD7Wrl1b7zEiJ6lIgLIkqHSEOxIREQmBZrewlJWVsX37dv9yfn4+n376KR07dqRLly7cfffdPPLII5x++ul0796dhx56iJycHK6++mr/MZdccgl5eXlMmzYNgBkzZjB58mTOPvtshg4dyoIFCygvL+fmm29u/RWKiIhI1Gt2wrJ582Yuuugi//KxviSTJ09m2bJl/PznP6e8vJzbb7+d4uJizj//fFavXo3Dcfw/3x07dnDo0CH/8vjx4zl48CCzZs3C6XQyaNAgVq9efVJHXBFpQ4ZRUyJt8oHPaH6ZstWgQ1oRWfHfkpBUFpoYRaTdaHbCMnLkSIwG/nCZTCbmzZvHvHnz6t1n165dJ62bNm2av8VFRMLM7cZwVeP+3/8gwYf1bBe445qctJjjPVi6ebk+/S9Umv8fDPRhWuELcdAiEsuiskpIRELMUzOuijOlE+4UK13M5d9taGLCYveCz4RnQwIucyJpZx3AlKKB5ESk5ZSwiEi93FYbLqsNo4XzMrtLbLjM6ggtIq2n2ZpFJOTMFi/mU710Sj9AiuNIuMMRkSikFhYRCSmLw01axhEsszzclryYorjOvLd1bLjDEpEooxYWEQkpi82LyevD+MCGe0MCKeYS7I7qcIclIlFGLSwi0iaMw2bc2LFSGe5QRCQKqYVFREREIp4SFhEREYl4SlhEREQk4ilhERERkYinhEVEREQinqqEJEodBEqA3YAnzLFILDJ53LBzZ83Czp3g9YY3IJF2TgmLRKGDUDURXEVgqgbfXqBzuIOSGJJSVozF6aToznvAasVcXYVxuBjcSo5FwkUJi0ShkppkZVMKxFdCXy9qZZFgiq+qwGW2sHDEjRRmd6Xf9s8Y//YS8KmVRSRclLBI9KpIoKmzB4u0RGHHLPZldiXz0P5whyLS7qnTrYiIiEQ8JSwiIiIS8fRISCRauN1Q6QbDBxVVUFICyZU1y9VV6PFYjHE6obg4cF1aGmRlhSMakbBTwiISDQwD79db8To8WM924dn6DaYdBr6B1Czn7wK7Oh7HDKeT8ivzqCotD1jtSE4kcdXrSlqkXVLCIhIVDLw+H87UDLIslRxK7EA6hylMziDLUsWhpA6kuwsxhTtMCY7iYqpKy3l25CQK07MByCwqYPq6l0gsLlbCIu2SEhaRKOK22DBMJjwWa81ynPX4sjvMwTWR2ewhteMRzN29ZGYU4ElJpEOnIkzpvnCHFnEK07PZl9k13GGIRAQlLCLSZizxHjJTnVx66SpSzi3j3tMe42BJJo4h1aScV0bSR6XhDlFEIpQSFhFpM2abF4vXi2dDPEaVFVsPN94P43GXWTD1AYejMtwhikiEUsIiUUTzB8UKz1ErRpUJE+AutWM+Gu6IRCTSKWGRKKH5gyS2abJFkYYpYZEIV6tVxVUImzpq/iCJOZpsUaRxSlgkgtXRqlLRGXCEOzCRoNJkiyKN09D8EsFqzcr8eRIYalWR2HZsssVDaRnhDkUk4qiFRSKfZmUWEWn31MIiIiIiEU8Ji4iIiEQ8JSwiIiIS8ZSwiIiISMRTp1sRiQxWgw5pRWTFf0tCUlm4oxGRCKOERSKQhuBvb8zxHizdvFyf/hcqzf8PBvowrdDszSJynBIWiTAagr89Mtu94DPh2ZCAy5xI2lkHMKWolF1EjlPCIhGm1mBxGoK/3XGX2HCZNZKxiJxMCYtEJg0WJyIitahKSERERCJe0BOWbt26YTKZTnpNnTq1zv2XLVt20r4Oh5qERURE5LigPxL6+OOP8XqPzzD65Zdf8v3vf5/rrruu3mNSUlLYunWrf9lkMgU7LBEREYliQU9YMjICZxl97LHH6NmzJyNGjKj3GJPJRFZWVrBDERERkRgR0j4sLpeLP//5z0yZMqXBVpOysjK6du1Kbm4uV111Ff/9738bPG91dTUlJSUBLxEREYldIU1YVq5cSXFxMTfddFO9+/Tu3ZslS5bwxhtv8Oc//xmfz8e5557Lvn376j1m/vz5pKam+l+5ubkhiF4kxrjdUFkJhg+qqzipCsswwGdARRVUV5+8XcLO5HHDzp3wzTc1L6cz3CGJtJmQljX/4Q9/YOzYseTk5NS7z/Dhwxk+fLh/+dxzz6VPnz787ne/4+GHH67zmJkzZzJjxgz/cklJiZIWkYYYBt6vt+J1eLCe7cKTvwvsx8e3ifN6MLndGG4X7v/9DxwerOcCYRps1mzxYj7VS6f0A3hSEjVUP5BSVozF6aToznvAagXAkZxI4qrXQY/UpR0IWcKye/du1qxZw4oVK5p1nNVq5ayzzmL79u317mO327Hb7a0NUaQdMfD6fDhTM8iyVHIoqQPp7kKOPai1eL34TOA2x7E3PYd4cylZlBGOVhaLw01axhEsszzclrwYt82hofqB+KoKXGYLC0fcSGF2VzKLCpi+7iUSi4uVsEi7ELJHQkuXLqVz585cdtllzTrO6/XyxRdfkJ2dHaLIRNovt8WGYTLhsVjr3sFkwhVnx2OxtW1gtVhsXkxeH8YHNire7oBrQyIJ1koN1f+dwo5Z7MvsSmG6/kZK+xKSFhafz8fSpUuZPHkycXGBbzFp0iROOeUU5s+fD8C8efP43ve+x2mnnUZxcTFPPPEEu3fv5tZbbw1FaCISJYzDZlw4MOwa31JEQpSwrFmzhj179jBlypSTtu3Zswez+fgfoCNHjnDbbbfhdDrp0KEDQ4YMYcOGDfTt2zcUoYmIiEgUCknC8oMf/ADDqLv5dt26dQHLTz31FE899VQowhAREZEYockPJUIcBEqA3Wh2ZpEQcTqhuPj4clqaOuxK1FDCIhHgIFRNBFcRmKrBtxfoHO6gRGKL00n5lXlUlZb7V6ksWqKJEhaJACU1ycqmFIivhL5e1MoiEmTFxVSVlvPsyEkUpmerLFqijhIWiRwVCWh0VZHQKkzPZl9m13CHIdJsqhcUERGRiKeERURERCKeHglJmByrCgJVBkljas8tVOLICHc4IhIGSlgkDGpVBYEqg6RBJ84tVBTXmfe2jg13WCLSxpSwSBjUqgqqSID0IlUGSb1qzy3kTk0gZWQJdkd1uMMSkTamPiwSPhUJUJYElY5wRyJRwDhsxn1Us7SLtFdKWERERCTiKWERERGRiKeERURERCKeOt2KxCwDqqug0gc+A+qZQV1EJBooYRGJQRafBwxw7doFB8F6tgvccUpaRCRqKWERiUFmnw8DcCZn4E6z0cV8bIZeJSwiEp3Uh0UkhrmtNlxWOwamcIciItIqSlhEJKqYzR5SOx7B3N1LUmJpuMMRkTaihEVEooYl3kNmqpNLL11FyrPlTLnmBVIcR8Idloi0AfVhEZGoYbZ5sXi9eDbEYzhtJOaVk2CrCHdYYWPyuGHnzuMr0tIgKyts8YiEkhIWEYk6nqNWjMPtu19OSlkxFqeTojvvAasVAEdyIomrXlfSIjFJCYuISBSKr6rAZbawcMSNFGZ3JbOogOnrXiKxuFgJi8QkJSwiIlGssGMW+zK7hjsMkZBTp1sRiVpmi5eMZCcdOhVhSveFOxwRCSG1sIhIdEo0SE8v4sdnPY2tl5uU88pI+khlziKxSgmLiEQnh4HF68O9MRFTmQtTH3A4KsMdlYiEiBIWaUMHgRJgN+AJcyxB4HZDpRsMH1RUgbWZT1gbO94watabNHlhQ9yldsxHwx1FjHI6obj4+LLKpiWMlLBIGzkIVRPBVQSmavDtBTqHO6iWMwy8X2/F6/BgPduF+3//w5wEccOamFQ0drzbjeGqxv2//0GCT5MXSttzOim/Mo+q0nL/KpVNSzgpYZE2UlKTrGxKgfhK6OslultZDLw+H87UDLIslThTOpHlOUDTJxds5HhPzWzLzpROuFOsmrxQ2l5xMVWl5Tw7chKF6dkqm5awU8IibasigVj60HVbbBgmE26rrUX5V2PH10xeaNPkhRI2henZKpuWiKCyZhEREYl4amERkdhgNeiQVkRW/LckJJWFOxoRCTIlLCIS9czxHizdvFyf/hcqzf8PBvowrdBAciKxRAmLhFiMlTJLRDLbveAz4dmQgMucSNpZBzClxE5fKRFRwiIhFWOlzBLx3CU2XGZHuMMQkRBQp1sJoVqlzJ8ngRHtpcwiIhIuamGR0IuxUmYREWl7amERERGRiKeERURERCKeHgmJiEjLaHJEaUNBb2GZM2cOJpMp4HXGGWc0eMxrr73GGWecgcPhYMCAAbz11lvBDktERILpu8kRi/LG+V/lV+bVJDEiIRCSFpZ+/fqxZs2a428SV//bbNiwgQkTJjB//nwuv/xyXnnlFa6++mo++eQT+vfvH4rwJOQ09opIzNPkiNLGQpKwxMXFkdXEH9inn36aMWPGcN999wHw8MMP89577/Hcc8+xePHiUIQnIaWxVyT8zBYv5lO9dEo/QIkjI9zhxDRNjihtJSSdbrdt20ZOTg49evRg4sSJ7Nmzp959N27cyKhRowLWjR49mo0bN9Z7THV1NSUlJQEviRQae0XCy+Jwk5ZxhORZldx21WLuHfmw5hYSiQFBT1iGDRvGsmXLWL16NYsWLSI/P58LLriA0tLSOvd3Op1kZmYGrMvMzMTZwHPQ+fPnk5qa6n/l5uYG9RokCCoSoFIjjkrbs9i8mLw+jA9suDckkGIuwe6oDndYItJKQX8kNHbsWP/XAwcOZNiwYXTt2pVXX32VW265JSjvMXPmTGbMmOFfLikpUdIiIgGMw2bc2LFSGe5Qwqd2Fc/OneD1hjUckdYIeVlzWloavXr1Yvv27XVuz8rKorCwMGBdYWFhg31g7HY7drs9qHGKhJzbDWVlkFwJPgMMjf4rIfRdFU9VaTkA5uoqjMPF4NYjWolOIR84rqysjB07dpCdnV3n9uHDh7N27dqAde+99x7Dhw8PdWgibccw8H69FdfHW3Bt/R+G21WTwChpkVCpVcXzyx/ez8tDr8YwfOBTK4tEp6AnLPfeey//+te/2LVrFxs2bCAvLw+LxcKECRMAmDRpEjNnzvTvf9ddd7F69WqefPJJvvnmG+bMmcPmzZuZNm1asEMTCSMDr89HfqdT2dvxFDxmi3+9SCgdq+I5lKZqKYluQX8ktG/fPiZMmEBRUREZGRmcf/75fPjhh2Rk1Pyy7NmzB7P5eJ507rnn8sorr/DLX/6SBx98kNNPP52VK1dqDBaJSdVWOz6rgYEp3KGIiESVoCcsy5cvb3D7unXrTlp33XXXcd111wU7FBEREYkRmvxQREREIp4mPxQRaadMHndNufMxLhfYbDVfqwxaIowSFhGRdiilrBiL00nRnfeA1YrJ48Z68ACuzllgsagMWiKOEhYRkXYovqoCl9nCwhE3UpjdlX7bP2P820tYeMHEgGWVQUukUB8WCZKDwA40Q7NEGrPZQ2rHI5i7e0lKrHuKkPassGNWQNnzicsikUItLBIEmqFZIpMl3kNmqpNLL11FyjnlTEl9gUc+eizcYYlIC6iFRYJAMzRLZDLbvFi8Xjwb4jH+bSPRWk6CrSLcYYlIC6iFRYKnIgGN3CqRyHPUinFYg/WJRDMlLCKhYhhQUQUmnyY7FBFpJSUsIqHgdmO4qnH/73+Q4MN6tgvccWBS0iIi0hJKWERCweMBA5wpnXCnWOliLq9Zr1YWEZEWUcIirXAQKEGlzPVzW224rDZNdigi0kpKWKSFVMos0cds8ZKR7KRDpyKNyyISZZSwSAvVKmWOr4S+KmWWCJdokJ5exI/PehpbLzcpozUui0g0UcIiraNSZokWDgOL14d7YyLefWB4jpB8bQld03fSoVMRpnRfuCOMeAGTJWpyRGljSlhEpF1xl9oxHwbDTmCLy3llJH2kR0T1OXGyRE2OKG1NCYuItE+1WlxMZS5MfcDhqAx3VBGrvskSNTmitBUNzS8i7Zq71I6n2BbuMKKGJkeUcFHCIiIiIhFPCYuIiIhEPCUsIiIiEvHU6Vaa4djItqDRbUPAMGomSayogrhqVC4uzaWyY4llSlikiWqNbAsa3TbILB4PJrcbw+2qmTDR4cF6LqChQdqO1aBDWhFZ8d+SkFQW7miaTWXHEuuUsEgT1RrZtiIB0os0um0QmX0+fCZwm+PYm55DvLmULMpQK0vbMMd7sHTzcn36X6g0/z8Y6MO0IrqyRZUdS6xTHxZpnooEKEuCSke4I4lNJhOuODsei8ps25LZ7gWfCc+GBFwbEkmwVmJKic5kUWXHEqvUwiIi8h13iQ2XWcm4SCRSC4uIiIhEPLWwiIhIaDidUFx8fDktDbKywre/RDUlLNKIY6XMKmMWkWZwOim/Mo+q0nL/KkdyIomrXq87qQj1/hL1lLBIHY4lKUVQ9XNwlaqMWdoVs8WL+VQvndIPUOJQ59UWKS6mqrScZ0dOojA9m8yiAqave4nE4uK6E4pQ7y9RTwmLnKDWeCumavDuhc0DIN6qMmZpFywON2kZR7DM8nBb8mKK4jrz3tax4Q4rahWmZ7Mvs2vE7C/RS51u5QS1xlv5PAkML1RYVcYs7YbF5sXk9WF8YMO9IYEUcwl2R3W4wxJp99TCInWrSECDlkl7Zhw248aOlcpwhyIiqIVFREREooBaWESOcbvB8NVMPmjyge+7r8vKILmyZnJCEZGWUhl2qyhhEQFwu/Fs/wbLoO8mH4z3Yh1SjXvrVthng97VWM+pxuR2o1+b9sVs9pDa8Qjm7l6SEkvDHY5EK5Vht5r+8ooAuL34fD58FkutyQdLcSZ3ojg7g7TUg+QapeD2ol+b9sMS7yEz1cmll64i5ZxypqS+wCMfPRbusCQaqQy71fSXVyRAzeSDVlNNVYjbaqPKnoBbkxG2S2abF4vXi2dDPIbTRmJeOQm2inCHJVFMZdgtp063IiKN8By1Yhw2hTsMkXYt6AnL/PnzOeecc0hOTqZz585cffXVbN26tcFjli1bhslkCng5HBr3Q0RERGoE/ZHQv/71L6ZOnco555yDx+PhwQcf5Ac/+AFfffUViYmJ9R6XkpISkNiYTPpvpm1pziARCS2Txw07dx5foSoZaYagJyyrV68OWF62bBmdO3dmy5YtXHjhhfUeZzKZyNIPbpicMBy/5gwSkSBLKSvG4nRSdOc9YLUCqpKR5gl5p9ujR48C0LFjxwb3Kysro2vXrvh8PgYPHsyjjz5Kv3796ty3urqa6urjQ2WXlJQEL+B2qdZw/PGVmjNIRIIuvqoCl9nCwhE3UpjdVVUy0mwh7XTr8/m4++67Oe+88+jfv3+9+/Xu3ZslS5bwxhtv8Oc//xmfz8e5557Lvn376tx//vz5pKam+l+5ubmhuoT2pSJBcwaJSEgVdsxiX2ZXCtOzwx2KRJmQJixTp07lyy+/ZPny5Q3uN3z4cCZNmsSgQYMYMWIEK1asICMjg9/97nd17j9z5kyOHj3qf+3duzcU4YuIiEiECNkjoWnTpvH3v/+d999/n1NPPbVZx1qtVs466yy2b99e53a73Y7dbg9GmCIiTWa2eMlIdtKhUxGmdF+4wxFpV4KesBiGwfTp03n99ddZt24d3bt3b/Y5vF4vX3zxBZdeemmwwxMRaZlEg/T0In581tPYerlJOa+MpI80VL9IWwl6wjJ16lReeeUV3njjDZKTk3E6nQCkpqYSHx8PwKRJkzjllFOYP38+APPmzeN73/sep512GsXFxTzxxBPs3r2bW2+9NdjhSXtmGMcnNjR8NZMdNutXwIDqKqj0gc84eTJEw6hZX1EFcdU1+0vscBhYvD7cGxMxlbkwDTTIztpHcXyWWly+E1C2vHMneL3BOx80vwxakw3GlKAnLIsWLQJg5MiRAeuXLl3KTTfdBMCePXswm493nzly5Ai33XYbTqeTDh06MGTIEDZs2EDfvn2DHZ60V243hqu6ZmLDBB/Ws134vt6KZUivJh1u8XnAANeuXXAQrGe7wB3nT1osHg8mtxvD/d3kiQ4P1nMBfYbFHHepnTiXB0s3L9en/4VK8/8jYUh5u29xObFs2VxdhXG4GNwtqzhsdRm0JhuMOSF5JNSYdevWBSw/9dRTPPXUU8EOReQ4T03C4UzphDvFSq5lG/h8WDxN+2Nq9vkwAGdyBu40G13Mx/4IGv7tPhO4zXG1Jk8sQ60sscls94LPhGdDAmVl6VitBqY+4HBUhju0sDmxbLnf9s8Y//YS8LWslaXVZdCabDDmaPLDdq39jW7rttpwWW1Ay0ZSrjnejlHf8abAyRMltrlLbFSXJOCxanLMY46VLWce2h/U87X4eE02GDOUsLQ7x5KUIqj6ObhKNbqtiIhEPCUs7coJQ/B798LmARBv1ei2IiIS0ZSwtCt1DMFfYUU/BiIidYi2KqNoi7eZ9EnVHlUkoM6gIkFmNeiQVkRW/LckJJWFOxpprWirMoq2eFtACYuISCuZ4wPLnBnow7RCNe1RLdqqjKIt3hZQwhKTjnWsBXABxyoY2k81kEhbql3m7DInknbWAUwpasWMBdFWZRRt8TaHEpaYU7tjrRss+8FzChCnaiCREHOX2HCZNeO5SCgoYYk5J3asrYItCVDREdKLVA0kIiJRSQlLrKrdsbbCAWVJkFDe4CEiIiKRSgmLxC63u2aSQ01GKG3MbPFiPtVLp/QDlDgywh1OzGjt5IqtnkzxRDFeRhxplLBIbHK78Wz/BssgTUYobcvicJOWcQTLLA+3JS+mKK4z720dG+6wol5rJ1ds9WSKJ2oHZcSRRgmLxCa3F5/Ph89i0WSE0qYsNi8mrw/jAxvu1ARSRpZgd2huqdZq7eSKrZ5M8UTtoIw40ihhkRinyQglPIzDZtzYsdJ+Z3AOhdZOrtjayRRPOl8MlxFHGiUsMaP9zbwsEg3MZg+pHY9g7u4lKbE03OGIRC0lLDHhhEkNNdaKSESwxHvITHVy6aWrSDmnnCmpL/DIR4+FOyyRqKSEJSbUMalhLLSy1K7yMfnAV+trw1ezXT/CEsHMNi8WrxfPhngMp43EvHISbBXhDititLbqJ+jnq131E4R4GjvfSVVLLhfYbPUvN7MKKehVUWGmv/axJJYmNTyxyifei3VINe6tWyHRwHq2C9/XW7EM6RXuSEUa5TlqxThsCncYEaW1VT9BP98JVT+tjaex850Yr8njxnrwAK7OWWCxnLQMzatCCnpVVARQwiKRqc4qn1KcyZ1wp9nItWwDnw+LJwZakqTdMFu8ZCQ76dCpCFN6+66xb23VT9DPd0LVT2vjaex89cW78IKJdS43twop6FVREUAJi0S4wCoft9WGy2oH9N+qRJlEg/T0In581tPYerlJOa+MpI/UCbe1VT/BPt+xqp+gxdPI+U6Mt77lFr9/kKuiwkkJS1RTZZBI1HAYWLw+3BsTMZW5MPUBh0MlzyJNpYQl6hxLUoqg6ufgKlVlkEgUcZfaMR8NdxQi0UcJS1Q5oXzZuxc2D4B4a+xUBomIiNRBCUtUqaN8ucKKbmPLmAwfVFfXlEhXVxEzFVYSHawGHdKKyIr/lvTMQszdayZL9KQkkpBUFu7opA6NlU0Hu0y7wfeH4JcpR/hkjvqkiwon9FWJpfLlsDEwudy48ndhrXbhyd8FdrVQSdswx3uwdPNyffpfqI57ncxLC7CNcXFb2mLcNgcM9GFa0b6riCJNY2XTwS7Tbuz9IchlylEwmaMSloinUWxDwgCfyYQzJYMsSxWHkjqQ7i5U7ZG0CbPdCz4Tng0JeFNsxJ3rwdhoo4IOGBlm0s46gClF/5REksbKpoNdpt3Y+we9TDkKJnNUwhKRjrWoAOwGVyFs6hhbo9hGCHecFcNkwmOxgjvc0Uh74y6x4TbbgZrJEl04MOxmzBYv5lNrHhGVODIoqeoQ5kjlmMbKpoNdpl3f+UMlkidzVMIScWq1qMDxVpWKzoAjrJGJSOhZHG7SMo5gmeXhtuTFHLV3YMmmn2iwOWn3lLBEnFodaysSIL1IrSoi7YjF5sXk9WF8YMObaaPn2G3cPewxbP012Jy0b0pYIkYdHWvLkiChvJHjwsgwWjcZodsNZWWQXBmcyQyrq6GyUlU/EhOMw2Z8qXFYvF4NNhcioa7qCbXmxt/gZItRcP1KWMIqigeBc7sxXNU1ExMm+Jo/GaFh4P16K97dFuhd3frJDN1uPJs+xtezAuvZqvqR2OIfbK5WKbRKn1sn1FU9odbc+BubbDEarl8JS8jU7jibAmScvD2aB4HzeMAAZ0on3CnWFkxGaOD1+cjv1JW4jlWtn8zQ7cXn8eJMzSDLUqmqH4k5tUuhK83/T6XPrRTqqp5Qa278TZ1sMZKvXwlLSJzQcdaWDo6XCUxaYmMQuJrJCG20dDLCaqsdn9Vo8fEnxWOxqepHYlLtUmiXOVGlz0ES6qqeUGtu/I1NthjJouvTMWrUSkYAhjnB8QXQlZNaWzQInIg0g7vEhsscWDGY4jhCh05FmLt7SUpUp1yJTUpYQqkiAWzVYNoNJXcBNrAlg+PXQBkR/9hHRCJeUmIpt49cTFZ1ASmjy5mS+gKPfPRYuMMSCTolLKEW5wG3F7YkgdUMQ/4DJbeAyYiOzrUiEpGODS6XnbWPNMth3BsSMA7ZSMwrJ8FWEe7wRIJOCUuzNdSZ9oTS5NoqHJBgHE9e4o2271zrdteU/PpLkZv5KOpYGXNZWU3LUXMfZdUug/YZzX9/EQECB5e7vuMrpCUf5UBZLsZhdTOX4An5ZIvNpISlWRrqTNuMOX8qHLR5v5Xqajxff4NlkOt4KfI51ZiaOvZJ7TLmvVY4vRLruUBTixTqKIPGHVfT0iQizVJ7cDn3qfFYLjqM2VTzy2i2eMlIdvr7tGRmFOBJSdRIudIsIZ9ssQWUsDRJrZaTY/P6wAmdaSN8zh+3G5/Ph89iYW96DlZbNblGaU2LT1N+DGqVMRdnd6JT8rdkUUaTE68TyqC7mL8bEE+tLCItZhw240m1HV+RaJCeXsSPz3oaWy83KZeXce9pj3GwJBPHkGqNlCtNFvLJFlvAHKoTL1y4kG7duuFwOBg2bBibNm1qcP/XXnuNM844A4fDwYABA3jrrbdCFVozfddyUjIOSu8E3y6oiAOP5Xhn2hO3VUbynD8mXHF23BZb47vWwW21UWVPwNOK411WO4ZGSBEJPoeBxevDvTGRyrfSMD6xYvO58X4Yj3tDAqYOBtlZ+8hK+Zb0zELM3WsmWDwlbZeqjKROx8qeC9Ozwx1KaFpY/vrXvzJjxgwWL17MsGHDWLBgAaNHj2br1q107nzyY5INGzYwYcIE5s+fz+WXX84rr7zC1VdfzSeffEL//v1DEWIz1DFeCh6Iq9UfpaKj5vwRkYjhLrVjPgyG14Tpu+U41/GB56rjXifz0gJsY1z8OH0hKZ1KqTg7QVVGEtFC0sLy29/+lttuu42bb76Zvn37snjxYhISEliyZEmd+z/99NOMGTOG++67jz59+vDwww8zePBgnnvuuVCE1zIVCXW3nFQ4aub8iehWFRFp72oPPOf91EGcz4Ox0Yb3Uzt2bzW+jQ6Mf9tItKrKSCJT0FtYXC4XW7ZsYebMmf51ZrOZUaNGsXHjxjqP2bhxIzNmzAhYN3r0aFauXFnn/tXV1VRXV/uXjx49CkBJSUmd+7dOKZR4wSgBXyWUGGCU1VS5HPvabAVfWd3bWvN1MM9rceO2eTFKffhMxXgMNyWlPkyew1Bhg6NeqC4CjJqvq0742lKFUerDYyrFbLbgNpVRUmrgMZXi9VVSUurDbHcT5zrS6PFen4XSUh8keDHcR/D63Ccf7zmM2+bxx+s2VTT8fp7DuFJceIxSSkt8uC3llNp8UFL38cfe30NZo/ubzXEnXW9zjq+9/7HrbenxtfcvSfW06vja+xt2I+a/X9F8vcG8xsrSatx4a46vMqgqdVFa4qOyzEVJlUFVsYsO3+4g8WAhpYaPNOcuXHhJPLhPy+14Oe1wIaVeL9ayMgjiZ+2xz22jKf0ZjSD79ttvDcDYsGFDwPr77rvPGDp0aJ3HWK1W45VXXglYt3DhQqNz58517j979myj5tNQL7300ksvvfSK9tfevXsbzS+iskpo5syZAS0yPp+Pw4cPk56ejskU/s6cJSUl5ObmsnfvXlJSUsIdjtSiexO5dG8il+5N5Ir2e2MYBqWlpeTk5DS6b9ATlk6dOmGxWCgsLAxYX1hYSFY9pVBZWVnN2t9ut2O32wPWpaWltTzoEElJSYnKH6D2QPcmcuneRC7dm8gVzfcmNTW1SfsFvdOtzWZjyJAhrF271r/O5/Oxdu1ahg8fXucxw4cPD9gf4L333qt3fxEREWlfQvJIaMaMGUyePJmzzz6boUOHsmDBAsrLy7n55psBmDRpEqeccgrz588H4K677mLEiBE8+eSTXHbZZSxfvpzNmzfzwgsvhCI8ERERiTIhSVjGjx/PwYMHmTVrFk6nk0GDBrF69WoyMzMB2LNnD2bz8cadc889l1deeYVf/vKXPPjgg5x++umsXLkyAsZgaRm73c7s2bNPemwl4ad7E7l0byKX7k3kak/3xmQYGhtdREREIlvIhuYXERERCRYlLCIiIhLxlLCIiIhIxFPCIiIiIhFPCUsTLFy4kG7duuFwOBg2bBibNm2qd9+RI0diMplOel122WX+fQzDYNasWWRnZxMfH8+oUaPYtm1bW1xKzAn2vbnppptO2j5mzJi2uJSY05x7A7BgwQJ69+5NfHw8ubm5/OxnP6OqqqpV55T6Bfv+zJkz56TfnTPOOCPUlxGTmnNv3G438+bNo2fPnjgcDs4880xWr17dqnNGrCZMD9SuLV++3LDZbMaSJUuM//73v8Ztt91mpKWlGYWFhXXuX1RUZBQUFPhfX375pWGxWIylS5f693nssceM1NRUY+XKlcZnn31mXHnllUb37t2NysrKNrqq2BCKezN58mRjzJgxAfsdPny4ja4odjT33rz88suG3W43Xn75ZSM/P9945513jOzsbONnP/tZi88p9QvF/Zk9e7bRr1+/gN+dgwcPttUlxYzm3puf//znRk5OjvHmm28aO3bsMJ5//nnD4XAYn3zySYvPGamUsDRi6NChxtSpU/3LXq/XyMnJMebPn9+k45966ikjOTnZKCsrMwzDMHw+n5GVlWU88cQT/n2Ki4sNu91u/OUvfwlu8DEu2PfGMGoSlquuuirYobY7zb03U6dONS6++OKAdTNmzDDOO++8Fp9T6heK+zN79mzjzDPPDEm87Ulz7012drbx3HPPBay75pprjIkTJ7b4nJFKj4Qa4HK52LJlC6NGjfKvM5vNjBo1io0bNzbpHH/4wx+4/vrrSUxMBCA/Px+n0xlwztTUVIYNG9bkc0po7s0x69ato3PnzvTu3Zuf/OQnFBUVBTX2WNeSe3PuueeyZcsWfzP1zp07eeutt7j00ktbfE6pWyjuzzHbtm0jJyeHHj16MHHiRPbs2RO6C4lBLbk31dXVOByOgHXx8fF88MEHLT5npIrK2ZrbyqFDh/B6vf4Reo/JzMzkm2++afT4TZs28eWXX/KHP/zBv87pdPrPceI5j22TxoXi3gCMGTOGa665hu7du7Njxw4efPBBxo4dy8aNG7FYLEG9hljVkntzww03cOjQIc4//3wMw8Dj8XDHHXfw4IMPtvicUrdQ3B+AYcOGsWzZMnr37k1BQQFz587lggsu4MsvvyQ5OTmk1xQrWnJvRo8ezW9/+1suvPBCevbsydq1a1mxYgVer7fF54xUamEJoT/84Q8MGDCAoUOHhjsUOUF99+b666/nyiuvZMCAAVx99dX8/e9/5+OPP2bdunXhCbSdWLduHY8++ijPP/88n3zyCStWrODNN9/k4YcfDndoQtPuz9ixY7nuuusYOHAgo0eP5q233qK4uJhXX301jJHHvqeffprTTz+dM844A5vNxrRp07j55psDpr+JFbF3RUHUqVMnLBYLhYWFAesLCwvJyspq8Njy8nKWL1/OLbfcErD+2HEtOaccF4p7U5cePXrQqVMntm/f3qp425OW3JuHHnqIG2+8kVtvvZUBAwaQl5fHo48+yvz58/H5fK263xIoFPenLmlpafTq1Uu/O83QknuTkZHBypUrKS8vZ/fu3XzzzTckJSXRo0ePFp8zUilhaYDNZmPIkCGsXbvWv87n87F27VqGDx/e4LGvvfYa1dXV/OhHPwpY3717d7KysgLOWVJSwkcffdToOeW4UNybuuzbt4+ioiKys7NbHXN70ZJ7U1FRcdJ/hMcewRmG0ar7LYFCcX/qUlZWxo4dO/S70wyt+Tl3OByccsopeDwe/va3v3HVVVe1+pwRJ7x9fiPf8uXLDbvdbixbtsz46quvjNtvv91IS0sznE6nYRiGceONNxoPPPDAScedf/75xvjx4+s852OPPWakpaUZb7zxhvH5558bV111lcqaWyDY96a0tNS49957jY0bNxr5+fnGmjVrjMGDBxunn366UVVVFfLriSXNvTezZ882kpOTjb/85S/Gzp07jXfffdfo2bOnMW7cuCafU5ouFPfnnnvuMdatW2fk5+cb69evN0aNGmV06tTJOHDgQJtfXzRr7r358MMPjb/97W/Gjh07jPfff9+4+OKLje7duxtHjhxp8jmjhRKWJnj22WeNLl26GDabzRg6dKjx4Ycf+reNGDHCmDx5csD+33zzjQEY7777bp3n8/l8xkMPPWRkZmYadrvduOSSS4ytW7eG8hJiVjDvTUVFhfGDH/zAyMjIMKxWq9G1a1fjtttui7pf6kjRnHvjdruNOXPmGD179jQcDoeRm5tr/PSnPw34o9vYOaV5gn1/xo8fb2RnZxs2m8045ZRTjPHjxxvbt29vwyuKHc25N+vWrTP69Olj2O12Iz093bjxxhuNb7/9tlnnjBYmw6inPU9EREQkQqgPi4iIiEQ8JSwiIiIS8ZSwiIiISMRTwiIiIiIRTwmLiIiIRDwlLCIiIhLxlLCIiIhIxFPCIiIiIhFPCYuIiIhEPCUsIiIiEvGUsIiIiEjEU8IiIiIiEe//A0AQNRNY1iDqAAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":"# Setting the minimum and maximum cosine similarity scores for matched authors\n\nmin_score = min(filtered_matching)\nmax_score = max(filtered_matching)","metadata":{"tags":[]},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"min_score, max_score","metadata":{"tags":[]},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":["(0.7180267572402954, 0.9124956727027892)"]},"metadata":{}}]},{"cell_type":"code","source":"# Setting the minimum and maximum cosine similarity scores for non matched authors\n\nmin_score_non_matching = min(filtered_non_matching)\nmax_score_non_matching = max(filtered_non_matching)","metadata":{"tags":[]},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"min_score_non_matching, max_score_non_matching","metadata":{"tags":[]},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":["(0.6938529014587402, 0.8471642732620239)"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Fine tuning","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import InputExample, losses\nfrom torch.utils.data import DataLoader","metadata":{"tags":[]},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"In the below section the LLM is fine tuned. There are two approaches adopted here. One will use the train_pairs/eval_pairs created earlier, in order to get a feel of the fit of the model when evaluated against an unseen dataset (the one we created using the train_test_split earlier). In the other I use the full_pairs dataset, where all of the data is used to then make predictions on the given dataset. ","metadata":{}},{"cell_type":"code","source":"train_examples = [\n    InputExample(texts=[\n        'query: ' + p.content1, 'query: ' + p.content2\n    ], label=float(p.label)) for p in train_pairs # use train_pairs if evaluating on the created eval_pairs set\n]\n\ntrain_dataloader = DataLoader(train_examples,  batch_size=4)\ntrain_loss = losses.ContrastiveLoss(model1)\n\nbatch_size = 4\nn_train_steps = len(train_examples) // batch_size\n\nmodel_params = {'train_objectives':[(train_dataloader, train_loss)],\n                'epochs':3, \n                'optimizer_params': {'lr':1e-04}, \n                'weight_decay':1e-4, \n                'scheduler':'warmupcosine', \n                'warmup_steps':int(0.2 * n_train_steps),\n               }\n\nprint('Fitting Model')\nmodel1.fit(**model_params)","metadata":{},"execution_count":39,"outputs":[{"name":"stdout","output_type":"stream","text":"Fitting Model\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9350c9228bc74ff890959d13e1291a09","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be82cdce47ea4c249c637ee24bb56fa4","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3baf2bc2a5ba4e33908056cc23b3ac7b","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6a2a085023f46cfba2eff52b19a4826","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Getting emotions","metadata":{}},{"cell_type":"markdown","source":"The idea behind this section is to augment the characteristics that can be extracted from the given texts, which characteristics could be used to identify whether the two given pieces of text are by the same author or not. \nFor this section a language model based on DistilRoBERTa-base created by Jochen Hartmann and published on Huggingface https://huggingface.co/j-hartmann/emotion-english-distilroberta-base/ will be used to extracted Ekman's 6 basic emotions, plus a neutral class:\n\n- anger \n- disgust \n- fear \n- joy \n- neutral \n- sadness \n- surprise ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__) # check your version of tensorflow as the more recent version might not be compatible with the model. I managed to make it work using version 2.12.1","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True,max_length=512, truncation=True,)","metadata":{"tags":[]},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"#### Emotions df for training set","metadata":{}},{"cell_type":"code","source":"emotion_cols = ['anger_1', 'disgust_1', 'fear_1', 'joy_1', 'neutral_1', 'sadness_1', 'surprise_1', 'anger_2', 'disgust_2', 'fear_2', 'joy_2', 'neutral_2', 'sadness_2', 'surprise_2']\n\nemotions_df = pd.DataFrame(columns = emotion_cols)","metadata":{"tags":[]},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for item in train_pairs:\n    \n    \n    # Extracting the emotions\n    emotion1 = classifier(item.content1)\n    emotion2 = classifier(item.content2)\n    \n    # Extracting and appending scores\n    scores1 = [item['score'] for item in emotion1[0]]\n    scores2 = [item['score'] for item in emotion2[0]]\n    row_scores = scores1+scores2\n    \n    # Append to existing emotions_df\n    emotions_df.loc[len(emotions_df)] = row_scores    \n    ","metadata":{"tags":[]},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"emotions_df.head()","metadata":{"tags":[]},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger_1</th>\n","      <th>disgust_1</th>\n","      <th>fear_1</th>\n","      <th>joy_1</th>\n","      <th>neutral_1</th>\n","      <th>sadness_1</th>\n","      <th>surprise_1</th>\n","      <th>anger_2</th>\n","      <th>disgust_2</th>\n","      <th>fear_2</th>\n","      <th>joy_2</th>\n","      <th>neutral_2</th>\n","      <th>sadness_2</th>\n","      <th>surprise_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.031457</td>\n","      <td>0.001329</td>\n","      <td>0.030010</td>\n","      <td>0.515784</td>\n","      <td>0.097630</td>\n","      <td>0.119717</td>\n","      <td>0.204073</td>\n","      <td>0.056074</td>\n","      <td>0.001951</td>\n","      <td>0.034739</td>\n","      <td>0.150114</td>\n","      <td>0.041628</td>\n","      <td>0.462255</td>\n","      <td>0.253238</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.139038</td>\n","      <td>0.002100</td>\n","      <td>0.059321</td>\n","      <td>0.527743</td>\n","      <td>0.063753</td>\n","      <td>0.056108</td>\n","      <td>0.151937</td>\n","      <td>0.044143</td>\n","      <td>0.001548</td>\n","      <td>0.054011</td>\n","      <td>0.565378</td>\n","      <td>0.049525</td>\n","      <td>0.088893</td>\n","      <td>0.196502</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.031457</td>\n","      <td>0.001329</td>\n","      <td>0.030010</td>\n","      <td>0.515784</td>\n","      <td>0.097630</td>\n","      <td>0.119717</td>\n","      <td>0.204073</td>\n","      <td>0.865456</td>\n","      <td>0.000753</td>\n","      <td>0.002677</td>\n","      <td>0.013111</td>\n","      <td>0.003037</td>\n","      <td>0.103889</td>\n","      <td>0.011077</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.056074</td>\n","      <td>0.001951</td>\n","      <td>0.034739</td>\n","      <td>0.150114</td>\n","      <td>0.041628</td>\n","      <td>0.462255</td>\n","      <td>0.253238</td>\n","      <td>0.865456</td>\n","      <td>0.000753</td>\n","      <td>0.002677</td>\n","      <td>0.013111</td>\n","      <td>0.003037</td>\n","      <td>0.103889</td>\n","      <td>0.011077</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.139038</td>\n","      <td>0.002100</td>\n","      <td>0.059321</td>\n","      <td>0.527743</td>\n","      <td>0.063753</td>\n","      <td>0.056108</td>\n","      <td>0.151937</td>\n","      <td>0.031457</td>\n","      <td>0.001329</td>\n","      <td>0.030010</td>\n","      <td>0.515784</td>\n","      <td>0.097630</td>\n","      <td>0.119717</td>\n","      <td>0.204073</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    anger_1  disgust_1    fear_1     joy_1  neutral_1  sadness_1  surprise_1  \\\n","0  0.031457   0.001329  0.030010  0.515784   0.097630   0.119717    0.204073   \n","1  0.139038   0.002100  0.059321  0.527743   0.063753   0.056108    0.151937   \n","2  0.031457   0.001329  0.030010  0.515784   0.097630   0.119717    0.204073   \n","3  0.056074   0.001951  0.034739  0.150114   0.041628   0.462255    0.253238   \n","4  0.139038   0.002100  0.059321  0.527743   0.063753   0.056108    0.151937   \n","\n","    anger_2  disgust_2    fear_2     joy_2  neutral_2  sadness_2  surprise_2  \n","0  0.056074   0.001951  0.034739  0.150114   0.041628   0.462255    0.253238  \n","1  0.044143   0.001548  0.054011  0.565378   0.049525   0.088893    0.196502  \n","2  0.865456   0.000753  0.002677  0.013111   0.003037   0.103889    0.011077  \n","3  0.865456   0.000753  0.002677  0.013111   0.003037   0.103889    0.011077  \n","4  0.031457   0.001329  0.030010  0.515784   0.097630   0.119717    0.204073  "]},"metadata":{}}]},{"cell_type":"markdown","source":"#### Emotions dataframe for evaluation set","metadata":{}},{"cell_type":"code","source":"eval_emotions_df = pd.DataFrame(columns = emotion_cols)","metadata":{"tags":[]},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"for item in eval_pairs:\n    \n    \n    # Extracting the emotions\n    emotion1 = classifier(item.content1)\n    emotion2 = classifier(item.content2)\n    \n    # Extracting and appending scores\n    scores1 = [item['score'] for item in emotion1[0]]\n    scores2 = [item['score'] for item in emotion2[0]]\n    row_scores = scores1+scores2\n    \n    # Append to existing emotions_df\n    eval_emotions_df.loc[len(eval_emotions_df)] = row_scores ","metadata":{"tags":[]},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"#### Emotions dataframe for full set","metadata":{}},{"cell_type":"code","source":"full_emotions_df = pd.DataFrame(columns = emotion_cols)","metadata":{"tags":[]},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for item in full_pairs:\n    \n    \n    # Extracting the emotions\n    emotion1 = classifier(item.content1)\n    emotion2 = classifier(item.content2)\n    \n    # Extracting and appending scores\n    scores1 = [item['score'] for item in emotion1[0]]\n    scores2 = [item['score'] for item in emotion2[0]]\n    row_scores = scores1+scores2\n    \n    # Append to existing emotions_df\n    full_emotions_df.loc[len(full_emotions_df)] = row_scores ","metadata":{"tags":[]},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"#### Getting cosine similarities for full set","metadata":{}},{"cell_type":"code","source":"corpus_full  = [e.content1 for e in full_pairs]\nquery_full = [q.content2 for q in full_pairs]\nfull_pairs_labels = [l.label for l in full_pairs]","metadata":{"tags":[]},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"Besides cosine similarity I have also calculated euclidean distance, correlation distance and manhattan distance","metadata":{}},{"cell_type":"code","source":"pred_scores_model1 = []\neuclid_distances = []\ncorr_distances = []\nmanhattan_distances = []\n\n# Getting cosine similarity scores from Model 1\n\nfor i in range(len(corpus_full)):\n    \n    corpus_embedding = model1.encode(corpus_full[i], convert_to_tensor=True, normalize_embeddings=True)\n    query_embedding = model1.encode(query_full[i], convert_to_tensor=True, normalize_embeddings=True)\n    cos_scores = util.cos_sim(query_embedding, corpus_embedding)[0]\n    euclid_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='euclidean' )[0][0]\n    corr_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='correlation' )[0][0]\n    manhattan_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='manhattan' )[0][0]\n    \n    pred_scores_model1.append(cos_scores.cpu().item())\n    euclid_distances.append(euclid_dist)\n    corr_distances.append(corr_dist)\n    manhattan_distances.append(manhattan_dist)\n    \nprint('Cosine Similarity Scores for Model 1 : done')","metadata":{"tags":[]},"execution_count":49,"outputs":[{"name":"stdout","output_type":"stream","text":"Cosine Similarity Scores for Model 1 : done\n"}]},{"cell_type":"code","source":"# Adding pairwise distances to the full_emotions dataframe\n\nfull_emotions_df['cossim'] = pred_scores_model1\nfull_emotions_df['euclid'] = euclid_distances\nfull_emotions_df['correlation'] = corr_distances\nfull_emotions_df['manhattan'] = manhattan_distances","metadata":{"tags":[]},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"#### Getting cosine similarities for training set","metadata":{}},{"cell_type":"code","source":"corpus_train  = [e.content1 for e in train_pairs]\nquery_train = [q.content2 for q in train_pairs]\ntrue_labels_train = [l.label for l in train_pairs]","metadata":{"tags":[]},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"pred_scores_model1 = []\neuclid_distances = []\ncorr_distances = []\nmanhattan_distances = []\n\n# Getting cosine similarity scores from Model 1\n\nfor i in range(len(corpus_train)):\n    \n    corpus_embedding = model1.encode(corpus_train[i], convert_to_tensor=True, normalize_embeddings=True)\n    query_embedding = model1.encode(query_train[i], convert_to_tensor=True, normalize_embeddings=True)\n    cos_scores = util.cos_sim(query_embedding, corpus_embedding)[0]\n    euclid_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='euclidean' )[0][0]\n    corr_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='correlation' )[0][0]\n    manhattan_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='manhattan' )[0][0]\n    \n    pred_scores_model1.append(cos_scores.cpu().item()) \n    euclid_distances.append(euclid_dist)\n    corr_distances.append(corr_dist)\n    manhattan_distances.append(manhattan_dist)\n    \nprint('Cosine Similarity Scores for Model 1 : done')","metadata":{"tags":[]},"execution_count":52,"outputs":[{"name":"stdout","output_type":"stream","text":"Cosine Similarity Scores for Model 1 : done\n"}]},{"cell_type":"code","source":"# Adding pairwise distances to training set\n\nemotions_df['cossim'] = pred_scores_model1\nemotions_df['euclid'] = euclid_distances\nemotions_df['correlation'] = corr_distances\nemotions_df['manhattan'] = manhattan_distances\n","metadata":{"tags":[]},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"#### Getting cosine similarities for evaluation set","metadata":{}},{"cell_type":"code","source":"corpus_eval  = [e.content1 for e in eval_pairs]\nquery_eval = [q.content2 for q in eval_pairs]\ntrue_labels_eval = [l.label for l in eval_pairs]","metadata":{"tags":[]},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"eval_pred_scores_model1 = []\neuclid_distances = []\ncorr_distances = []\nmanhattan_distances = []\n\n# Getting cosine similarity scores from Model 1\n\nfor i in range(len(corpus_eval)):\n    \n    corpus_embedding = model1.encode(corpus_eval[i], convert_to_tensor=True, normalize_embeddings=True)\n    query_embedding = model1.encode(query_eval[i], convert_to_tensor=True, normalize_embeddings=True)\n    cos_scores = util.cos_sim(query_embedding, corpus_embedding)[0]\n    euclid_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='euclidean' )[0][0]\n    corr_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='correlation' )[0][0]\n    manhattan_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='manhattan' )[0][0]\n        \n    eval_pred_scores_model1.append(cos_scores.cpu().item())\n    euclid_distances.append(euclid_dist)\n    corr_distances.append(corr_dist)\n    manhattan_distances.append(manhattan_dist)\n        \nprint('Cosine Similarity Scores for Model 1 : done')","metadata":{"tags":[]},"execution_count":55,"outputs":[{"name":"stdout","output_type":"stream","text":"Cosine Similarity Scores for Model 1 : done\n"}]},{"cell_type":"code","source":"# Adding pairwise distances to evaluation set\n\neval_emotions_df['cossim'] = eval_pred_scores_model1\neval_emotions_df['euclid'] = euclid_distances\neval_emotions_df['correlation'] = corr_distances\neval_emotions_df['manhattan'] = manhattan_distances","metadata":{"tags":[]},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### Preparing test set","metadata":{}},{"cell_type":"code","source":"test_df = test_df.join(test_texts_df.set_index('content_id'), on='content_id_1').rename({'content': 'content_1'}, axis=1)\ntest_df = test_df.join(test_texts_df.set_index('content_id'), on='content_id_2').rename({'content': 'content_2'}, axis=1)\ntest_df.head()","metadata":{"tags":[]},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prediction_id</th>\n","      <th>content_id_1</th>\n","      <th>content_id_2</th>\n","      <th>content_1</th>\n","      <th>content_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>195</td>\n","      <td>186</td>\n","      <td>The road to glory is currently a quiet one, it seems.  Welcome, Rahn'Keth.  I'm your private ...</td>\n","      <td>Service Corp International said the decision to withdraw its $2.9 billion hostile bid for Loewen...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>111</td>\n","      <td>145</td>\n","      <td>Well, Nigel is here...  He's scared as hell and just sitting in his cage. His ears are HU...</td>\n","      <td>To Lindsey:   I don't expect advice, but if it needs to be given, I'd really like to hear...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>80</td>\n","      <td>200</td>\n","      <td>Toronto stocks ended weaker in light trading on Thursday, swept lower by a downdraft in the oil ...</td>\n","      <td>The Toronto Stock Exchange's key index ended higher on Wednesday, but the overall market finishe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>71</td>\n","      <td>87</td>\n","      <td>Hope you dont have anything to do cos  urlLink these games  will keep you busy for a whil...</td>\n","      <td>sigh, i just got back from the doctors. They needled me. It still hurts. boo hoo. Yeah an...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>132</td>\n","      <td>67</td>\n","      <td>Interstate Bakeries Corp chairman Charles Sullivan said Thursday he backs analysts' earnings est...</td>\n","      <td>OEF  &amp;#151; Lance Cpl. Bryan P. Bertrand, 23, of Coos Bay, Oregon, was killed on...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   prediction_id  content_id_1  content_id_2  \\\n","0              0           195           186   \n","1              1           111           145   \n","2              2            80           200   \n","3              3            71            87   \n","4              4           132            67   \n","\n","                                                                                             content_1  \\\n","0     The road to glory is currently a quiet one, it seems.  Welcome, Rahn'Keth.  I'm your private ...   \n","1         Well, Nigel is here...  He's scared as hell and just sitting in his cage. His ears are HU...   \n","2  Toronto stocks ended weaker in light trading on Thursday, swept lower by a downdraft in the oil ...   \n","3         Hope you dont have anything to do cos  urlLink these games  will keep you busy for a whil...   \n","4  Interstate Bakeries Corp chairman Charles Sullivan said Thursday he backs analysts' earnings est...   \n","\n","                                                                                             content_2  \n","0  Service Corp International said the decision to withdraw its $2.9 billion hostile bid for Loewen...  \n","1         To Lindsey:   I don't expect advice, but if it needs to be given, I'd really like to hear...  \n","2  The Toronto Stock Exchange's key index ended higher on Wednesday, but the overall market finishe...  \n","3         sigh, i just got back from the doctors. They needled me. It still hurts. boo hoo. Yeah an...  \n","4                  OEF  &#151; Lance Cpl. Bryan P. Bertrand, 23, of Coos Bay, Oregon, was killed on...  "]},"metadata":{}}]},{"cell_type":"code","source":"test_df['content_1'] = test_df.content_1.apply(preprocess_text)\ntest_df['content_2'] = test_df.content_2.apply(preprocess_text)","metadata":{"tags":[]},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Prepare test data\nsentence_1_test = [i for i in test_df.content_1]\nsentence_2_test = [i for i in test_df.content_2]","metadata":{"tags":[]},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Calculating pairwise distances\n\ntest_pred_scores_model1 = []\neuclid_distances = []\ncorr_distances = []\nmanhattan_distances = []\n\n\nfor i in range(len(sentence_1_test)):\n    \n    corpus_embedding = model1.encode(sentence_1_test[i], convert_to_tensor=True, normalize_embeddings=True)\n    query_embedding = model1.encode(sentence_2_test[i], convert_to_tensor=True, normalize_embeddings=True)\n    cos_scores = util.cos_sim(query_embedding, corpus_embedding)[0]\n    euclid_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='euclidean' )[0][0]\n    corr_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='correlation' )[0][0]\n    manhattan_dist = pairwise_distances(corpus_embedding.cpu().reshape(1, -1) , query_embedding.cpu().reshape(1, -1), metric='manhattan' )[0][0]\n    \n    test_pred_scores_model1.append(cos_scores.cpu().item())\n    euclid_distances.append(euclid_dist)\n    corr_distances.append(corr_dist)\n    manhattan_distances.append(manhattan_dist)\n    \nprint('Finished pairwise distance calculations')","metadata":{"tags":[]},"execution_count":60,"outputs":[{"name":"stdout","output_type":"stream","text":"Finished pairwise distance calculations\n"}]},{"cell_type":"code","source":"# Creating test_emotions dataframe\n\ntest_emotions_df = pd.DataFrame(columns = emotion_cols)","metadata":{"tags":[]},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Extracting emotion scores for test set\n\nfor s1,s2 in zip(sentence_1_test, sentence_2_test):\n    \n    # Extracting the emotions\n    emotion1 = classifier(s1)\n    emotion2 = classifier(s2)\n    \n    # Extracting and appending scores\n    scores1 = [item['score'] for item in emotion1[0]]\n    scores2 = [item['score'] for item in emotion2[0]]\n    row_scores = scores1+scores2\n    \n    # Append to existing emotions_df\n    test_emotions_df.loc[len(test_emotions_df)] = row_scores ","metadata":{"tags":[]},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Adding pairwise distances to test_emotions dataframe\n\ntest_emotions_df['cossim'] = test_pred_scores_model1\ntest_emotions_df['euclid'] = euclid_distances\ntest_emotions_df['correlation'] = corr_distances\ntest_emotions_df['manhattan'] = manhattan_distances","metadata":{"tags":[]},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### Setting Model","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import  StratifiedKFold","metadata":{"tags":[]},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def get_best_prob(y_val, y_pred):\n    \n    '''\n    Takes in the true fold labels and fold predictions as parameters.\n    Returns the best probability threshold that maximizes accuracy.\n    '''\n    \n    best_threshold = None\n    best_accuracy_score = -np.inf\n\n    for threshold in np.linspace(0.01, 1.0, 99):\n           \n        preds = (y_pred > threshold).astype(int)\n        score = accuracy_score(y_val, preds)\n                \n        if score > best_accuracy_score:\n            best_accuracy_score = score\n            best_threshold = threshold\n        \n    print(f\"Best threshold for Accuracy found at probability: {best_threshold}\")\n    print(f'Accuracy : {best_accuracy_score}')\n      \n    return best_threshold","metadata":{"tags":[]},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Initialize and train the Models\n\ncat_model = CatBoostClassifier(learning_rate=0.003722251144453506, max_depth=2, random_seed=SEED, l2_leaf_reg=1.5350412246186924 ,loss_function='Logloss', n_estimators=900)\nrf_model = RandomForestClassifier(n_estimators=500, min_samples_leaf=9, n_jobs=-1, random_state=SEED)\nlgbm_model = LGBMClassifier(max_depth=3, learning_rate=0.02, boosting='gbdt', verbose=-1)\n\n# Initialize the StratifiedKFold\nn_splits = 3  # Number of folds for k-fold cross-validation\ncv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n\n# Lists to store the evaluation results for each fold\naccuracy_scores = []\n\ncat_pred = []\nrf_pred = []\nlgbm_pred = []\n\nbest_probs = []\n\nmodels = [cat_model,  rf_model,  lgbm_model]\nmodel_names = ['catboost',  'randomforest', 'lgbm']\n\nX = full_emotions_df.copy() # here set X as either emotions_df (if predicting eval_pairs) or full_emotions_df (if predicting test set)\ny = full_pairs_labels # here set y as true_labels_train if predicing eval_pairs or full_pairs_labels (if predicting test set)\nX_test = test_emotions_df.copy() # here set as eval_emotions_df (if predicting eval_pairs) or test_emotions_df (if predicting test set)\n\n\nfor model, name in zip(models, model_names):\n    \n    print()\n    print(f'Using {name}')\n    print('-------------')\n    \n    # Perform Stratified KFold cross-validation\n    for fold, (train_index, val_index) in enumerate(cv.split(X, y)):\n\n        print(f'==> Processing fold {fold+1}')\n\n        X_train, X_val = X.loc[train_index], X.loc[val_index]\n        y_train, y_val = [y[i] for i in train_index], [y[i] for i in val_index]\n\n        # Train the model on the training fold\n        if name == 'catboost':\n            model.fit(X_train, y_train, verbose=0, eval_set=(X_val, y_val), early_stopping_rounds=100)\n            \n        else:\n            model.fit(X_train, y_train)\n        \n\n        # Make predictions on the validation fold\n        y_pred = model.predict_proba(X_val)[:,1]\n        \n        # Make predictions on the test_set\n        test_preds = model.predict_proba(X_test)[:,1]\n        \n        \n        if name == 'catboost':\n            cat_pred.append(test_preds)\n        elif name == 'randomforest':\n            rf_pred.append(test_preds)\n        elif name == 'lgbm':\n            lgbm_pred.append(test_preds)\n\n        # Choosing the best probability threshold\n        best_prob = get_best_prob(y_val, y_pred)\n        fold_preds = (y_pred > best_prob).astype(int)\n        best_probs.append(best_prob)\n        \n        # Calculate accuracy for this fold and store it\n        accuracy = accuracy_score(y_val, fold_preds)\n        \n        accuracy_scores.append(accuracy)\n\n# Calculate the average accuracy across all folds\naverage_accuracy = sum(accuracy_scores) / len(accuracy_scores)\nprint()\nprint(\"Average Accuracy:\", average_accuracy)","metadata":{"tags":[]},"execution_count":68,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\nUsing catboost\n\n-------------\n\n==> Processing fold 1\n\nBest threshold for Accuracy found at probability: 0.1413265306122449\n\nAccuracy : 0.8949771689497716\n\n==> Processing fold 2\n\nBest threshold for Accuracy found at probability: 0.6868367346938775\n\nAccuracy : 0.9178082191780822\n\n==> Processing fold 3\n\nBest threshold for Accuracy found at probability: 0.6363265306122449\n\nAccuracy : 0.8899082568807339\n\n\n\nUsing randomforest\n\n-------------\n\n==> Processing fold 1\n\nBest threshold for Accuracy found at probability: 0.12112244897959183\n\nAccuracy : 0.8995433789954338\n\n==> Processing fold 2\n\nBest threshold for Accuracy found at probability: 0.4746938775510204\n\nAccuracy : 0.91324200913242\n\n==> Processing fold 3\n\nBest threshold for Accuracy found at probability: 0.5757142857142857\n\nAccuracy : 0.8899082568807339\n\n\n\nUsing lgbm\n\n-------------\n\n==> Processing fold 1\n\nBest threshold for Accuracy found at probability: 0.2423469387755102\n\nAccuracy : 0.8949771689497716\n\n==> Processing fold 2\n\nBest threshold for Accuracy found at probability: 0.45448979591836736\n\nAccuracy : 0.9178082191780822\n\n==> Processing fold 3\n\nBest threshold for Accuracy found at probability: 0.5656122448979591\n\nAccuracy : 0.8944954128440367\n\n\n\nAverage Accuracy: 0.9014075656654518\n"}]},{"cell_type":"markdown","source":"### Predictions for test set","metadata":{}},{"cell_type":"code","source":"cat_preds = np.mean(cat_pred,axis=0)\nrf_preds =  np.mean(rf_pred,axis=0)\nlgbm_preds = np.mean(lgbm_pred,axis=0)\ncomb_preds = np.mean([cat_preds,  rf_preds, lgbm_preds],axis=0)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction and submission","metadata":{}},{"cell_type":"code","source":"final_preds_df = sample_submission_df.copy()","metadata":{"tags":[]},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"final_preds_df['label'] = np.round(comb_preds,0).astype(int)\nfinal_preds_df.to_csv('tantus_submission.csv', index=False)\nfinal_preds_df.head()","metadata":{"tags":[]},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prediction_id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   prediction_id  label\n","0              0      0\n","1              1      1\n","2              2      1\n","3              3      0\n","4              4      0"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}